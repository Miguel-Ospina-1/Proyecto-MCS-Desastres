{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ac92a3bb-a68b-4d88-a748-231c2e57bbe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Este notebook tiene como objetivo hacer un control de calidad de  los datos de desastres naturales\n",
    "  # descargados desde el portal de datos abiertos de la UNGRD\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "98c106bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #importamos las librerías a utilizar\n",
    "# import pandas as pd\n",
    "# import numpy as np\n",
    "# import matplotlib.pyplot as plt\n",
    "# from matplotlib.patches import Rectangle\n",
    "# import matplotlib.patches as mpatches\n",
    "# import seaborn as sns \n",
    "# import datetime\n",
    "# import calendar\n",
    "# import matplotlib.dates as mdates\n",
    "# import re\n",
    "# from difflib import SequenceMatcher\n",
    "# from unidecode import unidecode\n",
    "# import unicodedata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6f963171",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importamos archivo de emergencias consolidadas de la UNGRD (2000-2023) para procesar info de desastres\n",
    "#df = pd.read_csv(\"Emergencias_puras_procesadas.csv\", encoding='latin1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "27e5d19e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separamos los municipios que están en una misma celda en filas diferentes\n",
    "         #Usar expresión regular para separar por \"-\" o \"/\" o \"- \"\n",
    "#df['MUNICIPIO'] = df['MUNICIPIO'].str.split(r'\\s*[-/]\\s*')\n",
    "# Explode para separar los municipios\n",
    "#df = df.explode('MUNICIPIO')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0cb02855",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creamos una función para eliminar los espacios antes y después del nombre en las columnas deseadas\n",
    " #Utilizamos el método strip para hacer esto\n",
    "\n",
    "# Seleccionar las columnas a las que se quiere aplicar el strip\n",
    "#cols_strip = ['DEPARTAMENTO', 'MUNICIPIO']\n",
    "\n",
    "# Aplicar str.strip() a las columnas seleccionadas\n",
    "#df[cols_strip] = df[cols_strip].apply(lambda x: x.str.strip())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "adf23c56",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Utilizamos una función para encontrar municipios que se parezcan en un 80% en su escritura para encontrar posibles errores\n",
    " #Si se encuentran municipios con más de 80% de coincidencia en un departamento se le pregunta al usuario si ambos municipios...\n",
    "    #son correctos, y si no lo son, se le pregunta cuál municipio quiere dejar, si A o B.\n",
    "    \n",
    "\n",
    "## Función para encontrar municipios similares\n",
    "#def encontrar_similares(df, threshold=0.8):\n",
    "#    municipios_corregidos = {}\n",
    "#    for departamento in df['DEPARTAMENTO'].unique():\n",
    "#        municipios = df[df['DEPARTAMENTO'] == departamento]['MUNICIPIO'].unique()\n",
    "#        for i, municipio1 in enumerate(municipios):\n",
    "#            for municipio2 in municipios[i+1:]:\n",
    "#                ratio = SequenceMatcher(None, municipio1, municipio2).ratio()\n",
    "#                if ratio >= threshold:\n",
    "#                    print(f\"Departamento: {departamento}\")\n",
    "#                    print(f\"Municipios similares: *{municipio1}* - *{municipio2}* (similitud: {ratio:.2f})\")\n",
    "#                    \n",
    "#                    # Pregunta si ambos municipios están correctos\n",
    "#                    respuesta = input(\"¿Ambos nombres son correctos? (si/no): \").lower()\n",
    "#                    \n",
    "#                    if respuesta == 'no':\n",
    "#                        correcto = input(f\"¿Cuál es el nombre correcto? (1 para '{municipio1}', 2 para '{municipio2}'): \")\n",
    "#                        if correcto == '1':\n",
    "#                            municipios_corregidos[municipio2] = municipio1\n",
    "#                        elif correcto == '2':\n",
    "#                            municipios_corregidos[municipio1] = municipio2\n",
    "#    \n",
    "#    return municipios_corregidos\n",
    "#\n",
    "\n",
    "## Función para reemplazar los municipios incorrectos por los correctos\n",
    "#def corregir_municipios(df, municipios_corregidos):\n",
    "#    df['MUNICIPIO'] = df['MUNICIPIO'].replace(municipios_corregidos)\n",
    "#    return df\n",
    "#\n",
    "## Encuentra los municipios similares\n",
    "#municipios_corregidos = encontrar_similares(df)\n",
    "#\n",
    "## Aplica las correcciones al DataFrame\n",
    "#df_corregido = corregir_municipios(df, municipios_corregidos)\n",
    "#\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "90e64f9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#exportamos a excel para verificar en profundidad\n",
    "#df.to_excel('C:/Users/migue/Proyecto_Col/Rtado_prueba/df_reemplazo_1.xlsx',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5d723d4a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    " #Se trabaja con el nuevo dataframe para terminar de hacer correciones\n",
    "    #El nuevo archivo tiene las correcciones de todo los pasos anteriores.\n",
    "\n",
    "##Se invoca el dataframe que se generó y corregió por medio de excel en el paso anterior\n",
    "# #Importamos el archivo del primer dataframe procesado\n",
    "#df2 = pd.read_csv(\"Reemplazo1_rev.csv\", encoding='latin1')\n",
    "#df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "84281e9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Hay separaciones de municipios que no se hicieron porque están separadas por comas y no se incluyo en el primer filtro\n",
    "##Este código separa los municipios que faltaron por separar incluyendo los que se separan por comas, ejm:\n",
    "#   #Cartagena, carmen, san jacinto...\n",
    "#    \n",
    "## Separamos los municipios que están en una misma celda en filas diferentes\n",
    "#         #Usar expresión regular para separar por \",\" \n",
    "#     #PERO APLICANDO LA EXCEPCIÓN DE BOGOTÁ.\n",
    "#        \n",
    "## Separar las filas que tienen \"BOGOTÁ, D.C.\" para no dividirlas\n",
    "#df_bogota = df2[df2['MUNICIPIO'] == 'BOGOTÁ, D.C.']\n",
    "#\n",
    "## Filtrar el resto del DataFrame que no contiene \"BOGOTÁ, D.C.\"\n",
    "#df_otros = df2[df2['MUNICIPIO'] != 'BOGOTÁ, D.C.']\n",
    "#\n",
    "## Aplicar el split y explode a las filas que no contienen \"BOGOTÁ, D.C.\"\n",
    "#df_otros['MUNICIPIO'] = df_otros['MUNICIPIO'].str.split(r'\\s*[,]\\s*')\n",
    "#df_otros = df_otros.explode('MUNICIPIO')\n",
    "#\n",
    "## Unir nuevamente las filas con \"BOGOTÁ, D.C.\" con el resto del DataFrame\n",
    "#df2 = pd.concat([df_bogota, df_otros], ignore_index=True)\n",
    "#\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3cf50946",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Ahora para no tener que exportar todo el dataframe a excel, creo un código para ver los municipios que están en un departamento\n",
    "#    #Ver municipios en un departamento para ver si funciona el código anterior \n",
    "#    \n",
    "## Filtrar los municipios de un departamento específico\n",
    "##depto = \"CUNDINAMARCA\"  # Cambia esto por el departamento de interes\n",
    "#mpios = df2[df2['DEPARTAMENTO'] == depto]['MUNICIPIO'].unique()\n",
    "#\n",
    "## Mostrar los municipios\n",
    "##print(f\"Municipios en el departamento de {depto}:\")\n",
    "##for mpio in mpios:\n",
    "##    print(mpio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ee0537f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Ahora voy a comparar los nombres de los departamentos y municipios que tengo en el dataframe con los datos oficiales\n",
    "# #Para eso uso un archivo de la base de datos abiertos de Colombia\n",
    "#\n",
    "##El archivo tiene caracteres especiales, por eso primero lo voy a procesar\n",
    "#   #El archivo va a quedar con tildes, sin caracteres especiales y en mayuscula\n",
    "#    \n",
    "## Cargar el archivo CSV (asegúrate de usar la codificación correcta)\n",
    "#df_oficial = pd.read_csv(\"Departamentos_Municipios_Colombia.csv\")\n",
    "#\n",
    "##Este código tranforma las tildes en formato UTF-8 a su forma normalizada (AmagÃ¡\" se convertirá a \"AMAGÁ\")\n",
    "#def corregir_nombre(valor):\n",
    "#    if isinstance(valor, str):  # Verifica si el valor es una cadena de texto\n",
    "#        # Normalizar la cadena a su forma compuesta y luego convertir a mayúsculas\n",
    "#        valor = unicodedata.normalize('NFC', valor).upper()\n",
    "#    return valor  # Retorna el valor original si no es una cadena de texto\n",
    "#\n",
    "## Aplicar la corrección a todas las columnas del DataFrame de datos oficiales \n",
    "#df_oficial = df_oficial.applymap(corregir_nombre)\n",
    "#\n",
    "##Aplicar la correción a todas las columnas del dataframde de datos de desastres\n",
    "#df2=df2.applymap(corregir_nombre)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0739d308",
   "metadata": {},
   "outputs": [],
   "source": [
    "#SE HACE UNA VERIFICACIÓN PARA VER LAS DIFERENCIAS ENTRE LOS DEPARTAMENTOS en df2 y df_oficial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9c8791ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Según la verificación anterior, voy a reemplazar el nombre de \"BOGOTA, D.C.\" por \"BOGOTÁ D.C.\" para unificar los nombres.\n",
    "# #Se reemplaza \"BOGOTA, D.C.\" por \"BOGOTÁ D.C.\" en df2 \n",
    "#    \n",
    "#df2['DEPARTAMENTO'] = df2['DEPARTAMENTO'].replace('BOGOTA, D.C.', 'BOGOTÁ D.C.')\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "87e95fcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Según la verificación de las diferencias entre dataframes, creamos código para reemplazar los nombres de los departamentos...\n",
    "# #...en el df de desastres que no tienen tilde respecto al de los datos abiertos (oficiales).\n",
    "#    \n",
    "#\n",
    "## Asegurarte de que ambas columnas de DEPARTAMENTO estén en mayúsculas y normalizadas para comparación\n",
    "#df2['DEPARTAMENTO'] = df2['DEPARTAMENTO'].str.upper()\n",
    "#df_oficial['DEPARTAMENTO'] = df_oficial['DEPARTAMENTO'].str.upper()\n",
    "#\n",
    "#def normalizar(texto):\n",
    "#    return unicodedata.normalize('NFKD', texto).encode('ASCII', 'ignore').decode('ASCII')\n",
    "#\n",
    "## Crear un diccionario para mapear los nombres de departamentos en df2 a los correctos en df_oficial\n",
    "#departamentos_oficiales = {normalizar(depto): depto for depto in df_oficial['DEPARTAMENTO']}\n",
    "#\n",
    "## Reemplazar los nombres en df2 por los correctos en df_oficial\n",
    "#df2['DEPARTAMENTO'] = df2['DEPARTAMENTO'].apply(lambda x: departamentos_oficiales.get(normalizar(x), x))\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1de05e64",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Ahora voy a comparar los datos de departamentos y municipios del df de desastres (df2) respecto al df de datos abiertos (df_oficial)\n",
    "# #para ver si los deptos y mpios sí coinciden \n",
    "#    \n",
    "##Primero verifico los departamentos:\n",
    "## Obtener los departamentos únicos en ambos DataFrames\n",
    "#departamentos_desastres = set(df2['DEPARTAMENTO'].unique())\n",
    "#departamentos_oficiales = set(df_oficial['DEPARTAMENTO'].unique())\n",
    "#\n",
    "## Encontrar los departamentos que están en desastres pero no en el oficial\n",
    "#departamentos_diferentes_desastres = departamentos_desastres - departamentos_oficiales\n",
    "#print(f\"Departamentos en el DataFrame de desastres que no están en el oficial: {departamentos_diferentes_desastres}\")\n",
    "#\n",
    "## Encontrar los departamentos que están en el oficial pero no en desastres\n",
    "#departamentos_diferentes_oficiales = departamentos_oficiales - departamentos_desastres\n",
    "#print(f\"Departamentos en el DataFrame oficial que no están en desastres: {departamentos_diferentes_oficiales}\")\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e66682b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "##En este código voy a unificar los nombres de los municipios según su nombre oficial (de acuerdo a datos abiertos del gobierno nal)\n",
    "# #Estandarizo el nombre de los municipios para que sean iguales en ambos dataframes\n",
    "#    #Utilizo la función normalizar usada anteriormente\n",
    "#    \n",
    "# # que ambas columnas de MUNICIPIO estén en mayúsculas para comparación\n",
    "#df2['MUNICIPIO'] = df2['MUNICIPIO'].str.upper()\n",
    "#df_oficial['MUNICIPIO'] = df_oficial['MUNICIPIO'].str.upper()\n",
    "#\n",
    "## Iterar sobre cada departamento en df2\n",
    "#for departamento in df2['DEPARTAMENTO'].unique():\n",
    "#    # Crear un diccionario para mapear los nombres de municipios en df2 a los correctos en df_oficial\n",
    "#    municipios_oficiales = {normalizar(mun): mun for mun in df_oficial[df_oficial['DEPARTAMENTO'] == departamento]['MUNICIPIO']}\n",
    "#    \n",
    "#    # Reemplazar los nombres en df2 por los correctos en df_oficial dentro del mismo departamento\n",
    "#    df2.loc[df2['DEPARTAMENTO'] == departamento, 'MUNICIPIO'] = df2[df2['DEPARTAMENTO'] == departamento]['MUNICIPIO'].apply(lambda x: municipios_oficiales.get(normalizar(x), x))\n",
    "#\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "109450bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "##EN ESTE CÓDIGO COMPARO LOS MUNICIPIOS QUE ESTÁN PRESENTES EN EL DF2 y no en el oficial y viceversa.\n",
    "#\n",
    "## Obtener los departamentos únicos en ambos DataFrames\n",
    "#departamentos_desastres = set(df2['DEPARTAMENTO'].unique())\n",
    "#departamentos_oficiales = set(df_oficial['DEPARTAMENTO'].unique())\n",
    "#\n",
    "## Encontrar los departamentos que están en desastres pero no en el oficial\n",
    "#departamentos_diferentes_desastres = departamentos_desastres - departamentos_oficiales\n",
    "#print(f\"Departamentos en el DataFrame de desastres que no están en el oficial: {departamentos_diferentes_desastres}\")\n",
    "#\n",
    "## Encontrar los departamentos que están en el oficial pero no en desastres\n",
    "#departamentos_diferentes_oficiales = departamentos_oficiales - departamentos_desastres\n",
    "#print(f\"Departamentos en el DataFrame oficial que no están en desastres: {departamentos_diferentes_oficiales}\")\n",
    "#\n",
    "#\n",
    "## Crear un diccionario para almacenar las diferencias en municipios por departamento\n",
    "#municipios_diferencias = {}\n",
    "#\n",
    "## Iterar sobre cada departamento del DataFrame oficial\n",
    "#for departamento in departamentos_oficiales:\n",
    "#    # Obtener los municipios únicos en el DataFrame de desastres para este departamento\n",
    "#    municipios_desastres = set(df2[df2['DEPARTAMENTO'] == departamento]['MUNICIPIO'].unique())\n",
    "#    \n",
    "#    # Obtener los municipios únicos en el DataFrame oficial para este departamento\n",
    "#    municipios_oficiales = set(df_oficial[df_oficial['DEPARTAMENTO'] == departamento]['MUNICIPIO'].unique())\n",
    "#    \n",
    "#    # Encontrar las diferencias\n",
    "#    municipios_diferentes_desastres = municipios_desastres - municipios_oficiales\n",
    "#    municipios_diferentes_oficiales = municipios_oficiales - municipios_desastres\n",
    "#    \n",
    "#    # Almacenar las diferencias si existen\n",
    "#    if municipios_diferentes_desastres or municipios_diferentes_oficiales:\n",
    "#        municipios_diferencias[departamento] = {\n",
    "#            \"Solo en desastres\": municipios_diferentes_desastres,\n",
    "#            \"Solo en oficial\": municipios_diferentes_oficiales\n",
    "#        }\n",
    "#\n",
    "## Mostrar las diferencias encontradas\n",
    "#for departamento, diferencias in municipios_diferencias.items():\n",
    "#    print(f\"\\nDepartamento: {departamento}\")\n",
    "#    print(f\"Municipios solo en desastres: {diferencias['Solo en desastres']}\")\n",
    "#    print(f\"Municipios solo en oficial: {diferencias['Solo en oficial']}\")\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b19d055b",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Exporto ambos dataframes para tratar manualmente las diferencias\n",
    "#\n",
    "#df2.to_excel('C:/Users/migue/Proyecto_Col/Rtado_prueba/df_reemplazo_2.xlsx',index=False)\n",
    "#df_oficial.to_excel('C:/Users/migue/Proyecto_Col/Rtado_prueba/df_oficial_procesado.xlsx',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d1c4cab0",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Ahora como control de calidad de los datos se van a eliminar las celdas que tengan como municipio = \"DEPARTAMENTO\" o \"VARIOS\"\n",
    "#    #también las que tengan celdas vacías o departamento=NACION\n",
    "##Importamos el nuevo dataframe llamado Revision2.csv y lo nombramos df3\n",
    "#\n",
    "#df3=pd.read_csv(\"Rtado_prueba/Revision2_nvo.csv\", encoding='latin1')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d2b64cc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Ahora procedo a eliminar las celdas vacías de la columna \"DEPARTAMENTO\" y los registros que tengan \"NACION\" como departamento\"\n",
    "# #También elimino las filas donde el departamento esté vacío\n",
    "#\n",
    "## Eliminar filas donde el departamento es \"NACION\"\n",
    "#df3 = df3[df3['DEPARTAMENTO'] != 'NACION']\n",
    "#\n",
    "## Eliminar filas donde la columna \"DEPARTAMENTO\" tiene valores vacíos o NaN\n",
    "#df3 = df3.dropna(subset=['DEPARTAMENTO'])\n",
    "#\n",
    "## O también puedes eliminar filas donde la columna \"DEPARTAMENTO\" está vacía\n",
    "#df3 = df3[df3['DEPARTAMENTO'].str.strip() != '']\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c6135d77",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Ahora elimino las filas que tengan como municipio=DEPARTAMENTO (control de calidad de datos)\n",
    "# #También las que tengan columnas de municipio=VARIOS\n",
    "#\n",
    "#df3 = df3[df3['MUNICIPIO'] != 'DEPARTAMENTO']\n",
    "#df3 = df3[df3['MUNICIPIO'] != 'VARIOS']\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "29f4bebd",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Se carga archivo del DANE para observar diferencias en departamentos y municipios, luego se añaden los códigos del DANE\n",
    "#\n",
    "#\n",
    "##Se comparan los departamentos primero\n",
    "## Cargar el archivo CSV (asegúrate de usar la codificación correcta)\n",
    "#df_oficial = pd.read_csv(\"Rtado_prueba/df_oficial_procesado.csv\", encoding='latin1')\n",
    "#    \n",
    "## Obtener los departamentos únicos en ambos DataFrames\n",
    "#departamentos_desastres = set(df3['DEPARTAMENTO'].unique())\n",
    "#departamentos_oficiales = set(df_oficial['DEPARTAMENTO'].unique())\n",
    "#\n",
    "## Encontrar los departamentos que están en desastres pero no en el oficial\n",
    "#departamentos_diferentes_desastres = departamentos_desastres - departamentos_oficiales\n",
    "#print(f\"Departamentos en el DataFrame de desastres que no están en el oficial: {departamentos_diferentes_desastres}\")\n",
    "#\n",
    "## Encontrar los departamentos que están en el oficial pero no en desastres\n",
    "#departamentos_diferentes_oficiales = departamentos_oficiales - departamentos_desastres\n",
    "#print(f\"Departamentos en el DataFrame oficial que no están en desastres: {departamentos_diferentes_oficiales}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4c518dd8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "##Ahora se comparan los municipios para observar diferencias\n",
    "## Crear un diccionario para almacenar las diferencias en municipios por departamento\n",
    "#municipios_diferencias = {}\n",
    "#\n",
    "## Iterar sobre cada departamento del DataFrame oficial\n",
    "#for departamento in departamentos_oficiales:\n",
    "#    # Obtener los municipios únicos en el DataFrame de desastres para este departamento\n",
    "#    municipios_desastres = set(df3[df3['DEPARTAMENTO'] == departamento]['MUNICIPIO'].unique())\n",
    "#    \n",
    "#    # Obtener los municipios únicos en el DataFrame oficial para este departamento\n",
    "#    municipios_oficiales = set(df_oficial[df_oficial['DEPARTAMENTO'] == departamento]['MUNICIPIO'].unique())\n",
    "#    \n",
    "#    # Encontrar las diferencias\n",
    "#    municipios_diferentes_desastres = municipios_desastres - municipios_oficiales\n",
    "#    municipios_diferentes_oficiales = municipios_oficiales - municipios_desastres\n",
    "#    \n",
    "#    # Almacenar las diferencias si existen\n",
    "#    if municipios_diferentes_desastres or municipios_diferentes_oficiales:\n",
    "#        municipios_diferencias[departamento] = {\n",
    "#            \"Solo en desastres\": municipios_diferentes_desastres,\n",
    "#            \"Solo en oficial\": municipios_diferentes_oficiales\n",
    "#        }\n",
    "#\n",
    "## Mostrar las diferencias encontradas\n",
    "#for departamento, diferencias in municipios_diferencias.items():\n",
    "#    print(f\"\\nDepartamento: {departamento}\")\n",
    "#    print(f\"Municipios solo en desastres: {diferencias['Solo en desastres']}\")\n",
    "#    print(f\"Municipios solo en oficial: {diferencias['Solo en oficial']}\")\n",
    "#    \n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "fa7765b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "193f62cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Ahora elimino las filas que tengan eso en MUNICIPIO= \"GOBERNACIÓN\",'OCÉANO PACÍFICO', o nan\n",
    "#\n",
    "## Eliminar filas donde el municipio es \"GOBERNACIÓN\", \"OCÉANO PACÍFICO\" o NaN\n",
    "#df3 = df3[~df3['MUNICIPIO'].isin(['GOBERNACIÓN', 'OCÉANO PACÍFICO','VAUPES'])]\n",
    "#\n",
    "## Eliminar filas donde el municipio es NaN\n",
    "#df3 = df3.dropna(subset=['MUNICIPIO'])\n",
    "#df3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f823241e",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Elimino las columnas sin nombre y vacías\n",
    "#\n",
    "#df3 = df3.drop(columns=['Unnamed: 12','Unnamed: 13'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "6b49c5a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Ahora agrego las columnas de los códigos del DANE como identificadores a df3, para departamentos y municipios.\n",
    "# #Esto para luego tener formas de identificar los municipios de manera más fácil\n",
    "#    \n",
    "#\n",
    "## Crear una columna combinada de \"DEPARTAMENTO\" y \"MUNICIPIO\" en df_oficial\n",
    "#df_oficial['DEP_MUN'] = df_oficial['DEPARTAMENTO'] + \"_\" + df_oficial['MUNICIPIO']\n",
    "#\n",
    "## Crear una columna combinada de \"DEPARTAMENTO\" y \"MUNICIPIO\" en df3\n",
    "#df3['DEP_MUN'] = df3['DEPARTAMENTO'] + \"_\" + df3['MUNICIPIO']\n",
    "#\n",
    "## Crear un diccionario que mapea la columna combinada a \"CÓDIGO DANE DEL MUNICIPIO\"\n",
    "#codigo_dane_map = df_oficial.set_index('DEP_MUN')['CÓDIGO DANE DEL MUNICIPIO'].to_dict()\n",
    "#\n",
    "## Crear la nueva columna \"CÓDIGO DANE\" en df3 usando el diccionario de mapeo\n",
    "#df3['CÓDIGO DANE'] = df3['DEP_MUN'].map(codigo_dane_map)\n",
    "#\n",
    "## Eliminar la columna temporal 'DEP_MUN' si ya no es necesaria\n",
    "#df3.drop(columns=['DEP_MUN'], inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "8420a90c",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Como los municipios que están diferente en df3 respecto a los nombres oficiales en el DANE se verificaron uno por uno\n",
    "# #con el nombre de su sitio oficial y en df3 está el correcto, entonces se hacen las equivalencias respectivas \n",
    "#    #con el código del municipio en el df_oficial (DANE) pero con el nombre de df3 que es el oficial de su pag web\n",
    "#     #o sea, se agrega al df3 la columna de código DANE del mpio pero con el nombre df3\n",
    "#        \n",
    "## Diccionario de equivalencias municipio en df3 : municipio en df_oficial\n",
    "#equivalencias_municipios = {\n",
    "#    # CAUCA\n",
    "#    'LOPEZ DE MICAY': 'LÓPEZ',\n",
    "#    # MAGDALENA\n",
    "#    'PUEBLOVIEJO': 'PUEBLO VIEJO',\n",
    "#    'CERRO DE SAN ANTONIO': 'CERRO SAN ANTONIO',\n",
    "#    # SUCRE\n",
    "#    'TOLUVIEJO': 'TOLÚ VIEJO',\n",
    "#    # META\n",
    "#    'VISTAHERMOSA': 'VISTA HERMOSA',\n",
    "#    # HUILA\n",
    "#    'EL AGRADO': 'AGRADO',\n",
    "#    'EL PITAL': 'PITAL',\n",
    "#    \n",
    "#    # CUNDINAMARCA\n",
    "#    'SAN JUAN DE RIOSECO': 'SAN JUAN DE RÍO SECO',\n",
    "#    'UBATE': 'VILLA DE SAN DIEGO DE UBATE',\n",
    "#    # PUTUMAYO\n",
    "#    'PUERTO LEGUÍZAMO': 'LEGUÍZAMO',\n",
    "#    'VALLE DEL GUAMUEZ': 'VALLE DE GUAMEZ',\n",
    "#    # BOLÍVAR\n",
    "#    'MOMPOX': 'MOMPÓS',\n",
    "#    'SAN PABLO': 'SAN PABLO DE BORBUR',\n",
    "#    # ANTIOQUIA\n",
    "#    'SANTA FE DE ANTIOQUIA': 'SANTAFÉ DE ANTIOQUIA',\n",
    "#    'SAN VICENTE FERRER': 'SAN VICENTE',\n",
    "#    'EL RETIRO': 'RETIRO',\n",
    "#    'SAN PEDRO DE LOS MILAGROS': 'SAN PEDRO',\n",
    "#    'EL PEÑOL': 'PEÑOL',\n",
    "#    # LA GUAJIRA\n",
    "#    'DIBULLA': 'DIBULA',\n",
    "#    # NARIÑO\n",
    "#    'MAGUI PAYAN': 'MAGÜÍ',\n",
    "#    'EL CONTADERO': 'CONTADERO',\n",
    "#    # GUAINÍA\n",
    "#    'BARRANCOMINAS': 'BARRANCO MINAS',\n",
    "#    # CÓRDOBA\n",
    "#    'SAN ANDRÉS DE SOTAVENTO': 'SAN ANDRÉS SOTAVENTO',\n",
    "#    # TOLIMA\n",
    "#    'EL ESPINAL': 'ESPINAL',\n",
    "#    'RIOBLANCO': 'RIO BLANCO',\n",
    "#    # BOYACÁ\n",
    "#    'BUENAVISTA': 'BUENA VISTA'\n",
    "#}\n",
    "#\n",
    "#\n",
    "## Crear una copia del df_oficial con las columnas relevantes\n",
    "#df_oficial_reducido = df_oficial[['DEPARTAMENTO', 'MUNICIPIO', 'CÓDIGO DANE DEL MUNICIPIO']].copy()\n",
    "#\n",
    "## Reemplazar los nombres de los municipios en df3 según las equivalencias para la comparación\n",
    "#df3['MUNICIPIO_EQUIVALENTE'] = df3['MUNICIPIO'].replace(equivalencias_municipios)\n",
    "#\n",
    "## Realizar la unión (merge) usando las equivalencias en la columna \"MUNICIPIO_EQUIVALENTE\"\n",
    "#df3 = df3.merge(df_oficial_reducido, \n",
    "#                left_on=['DEPARTAMENTO', 'MUNICIPIO_EQUIVALENTE'], \n",
    "#                right_on=['DEPARTAMENTO', 'MUNICIPIO'], \n",
    "#                how='left', \n",
    "#                suffixes=('', '_OFICIAL'))\n",
    "#\n",
    "## Eliminar la columna temporal \"MUNICIPIO_EQUIVALENTE\" y la columna \"MUNICIPIO_OFICIAL\"\n",
    "#df3 = df3.drop(columns=['MUNICIPIO_EQUIVALENTE', 'MUNICIPIO_OFICIAL'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "01ccfb33",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Hay un error en el df oficial respeto a SAN LUIS DE PALENQUE  en CASANARE, lo tienen como SAN LUIS DE GACENO\n",
    "# #Se pone el código oficial del municipio en la columna CÓDIGO DANE DEL MUNICIPIO_OFICIAL\n",
    "#    \n",
    "##También SANTA CATALINA no figura como municipio entonces lo elimino, además de solo tener un registro\n",
    "#\n",
    "#\n",
    "## Condición para encontrar las filas donde el municipio es \"SAN LUIS DE PALENQUE\"\n",
    "#condicion = (df3['MUNICIPIO'] == 'SAN LUIS DE PALENQUE') & (df3['DEPARTAMENTO'] == 'CASANARE')\n",
    "#\n",
    "## Asignar el código DANE correcto como float\n",
    "#df3.loc[condicion, 'CÓDIGO DANE'] = float('85.325')\n",
    "#\n",
    "##Ahora elimino a SANTA CATALINA EN el depto de san andrés\n",
    "## Crear la condición para las filas a eliminar\n",
    "#condicion_eliminar = (df3['MUNICIPIO'] == 'SANTA CATALINA') & (df3['DEPARTAMENTO'] == 'ARCHIPIÉLAGO DE SAN ANDRÉS, PROVIDENCIA Y SANTA CATALINA')\n",
    "#\n",
    "## Eliminar las filas que cumplen con la condición\n",
    "#df3 = df3[~condicion_eliminar]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "2ca44226",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Por último, elimino la columna CÓDIGO DANE porque la columna CÓDIGO DANE DEL MUNICIPIO contiene todos los códigos\n",
    "#\n",
    "## Eliminar la columna \"CÓDIGO DANE DEL MUNICIPIO\"\n",
    "#df3 = df3.drop(columns=['CÓDIGO DANE'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "dea4d254",
   "metadata": {},
   "outputs": [],
   "source": [
    "#GUARDAMOS ESTE PROCESAMIENTO como df_mundep\n",
    "\n",
    "#df3.to_csv('Rtado_prueba/df_mundep.csv',index=False)\n",
    "#df3.to_excel('Rtado_prueba/df_mundep.xlsx',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "8301a2d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#  #Ahora voy a procesar los tipos de evento\n",
    "# df4=pd.read_csv(\"Rtado_prueba/df_mundep.csv\", encoding='UTF-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "615fcf57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #primero nos aseguramos de que no hayan espacios antes y después del nombre en tipo de evento, usamos strip\n",
    "# # Seleccionar las columnas a las que se quiere aplicar el strip\n",
    "# cols_strip = ['TIPO DE EVENTO']\n",
    "\n",
    "# # Aplicar str.strip() a las columnas seleccionadas\n",
    "# df4[cols_strip] = df4[cols_strip].apply(lambda x: x.str.strip())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "dd58cac8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Ahora me aseguro de que se unifique la escritura con y sin tilde (ejm: INUNDACIÓN-INUNDACION)\n",
    "\n",
    "# from unidecode import unidecode\n",
    "\n",
    "# # Crear un diccionario para almacenar el mapeo de eventos originales con tilde\n",
    "# eventos_con_tilde = {}\n",
    "\n",
    "# # Iterar sobre los eventos únicos en la columna 'TIPO DE EVENTO'\n",
    "# for evento in df4['TIPO DE EVENTO'].unique():\n",
    "#     # Convertir el evento a su versión sin tildes\n",
    "#     evento_sin_tilde = unidecode(evento)\n",
    "    \n",
    "#     # Si la versión sin tilde ya está en el diccionario, mantener el evento original con tilde\n",
    "#     if evento_sin_tilde not in eventos_con_tilde:\n",
    "#         eventos_con_tilde[evento_sin_tilde] = evento\n",
    "\n",
    "# # Reemplazar en la columna 'TIPO DE EVENTO' los eventos por su versión con tilde\n",
    "# df4['TIPO DE EVENTO'] = df4['TIPO DE EVENTO'].apply(lambda x: eventos_con_tilde[unidecode(x)])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "d954a014",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Ahora elimino los eventos que no corresponden a la categoría o están mal categorizados:\n",
    "\n",
    "# # Lista de eventos que deseas eliminar\n",
    "# eventos_a_eliminar = [\n",
    "#     'RESCATE EN MONTAÑA', 'SEQUIA/INCENDIOS FORESTALES', 'ANTROPICO', 'EPIDEMIA',\n",
    "#     'VENDAVAL-INCENDIO ESTRUCTURAL', 'EROSION-INCENDIO ESTRUCTURAL', 'INTOXICACION', 'AR',\n",
    "#     'ANTROPOGENICO NO INTENCIONAL', 'INCENDIO - OTROS', 'CAIDA DE ARBOL', 'DESAPARECIDO',\n",
    "#     'SOCAVACION', 'EVENTO MAYOR', 'MAREA ALTA', 'CASO FORTUITO', 'IMERSION', 'CONATO',\n",
    "#     'DIAPIRISMO', 'COVID-19', 'CICLON TROPICAL: DEPRESION/TORMENTA/HURACAN', 'QUEMA', 'DAÑO',\n",
    "#     'AMENAZAS CONCATENADAS O COMPLEJAS', 'CICLÓN, TROPICAL, DEPRESIÓN/TORMENTA/HURACÁN'\n",
    "# ]\n",
    "\n",
    "# # Filtrar el DataFrame para eliminar las filas con los eventos especificados\n",
    "# df4 = df4[~df4['TIPO DE EVENTO'].isin(eventos_a_eliminar)]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "34aa6600",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Ahora realizo los reemplazos que correspondan según las categorías\n",
    "\n",
    "# # Diccionario de reemplazos para unificar los desastres naturales\n",
    "# reemplazos_unificacion = {\n",
    "#     'AVALANCHA': 'MOVIMIENTO EN MASA',\n",
    "#     'REMOCION EN MASA': 'MOVIMIENTO EN MASA',\n",
    "#     'DELIZAMIENTO': 'MOVIMIENTO EN MASA',\n",
    "#     'DESLIZAMIENTO': 'MOVIMIENTO EN MASA',\n",
    "#     'ERUPCION': 'ERUPCIÓN VOLCÁNICA',\n",
    "#     'ERUPCIÓN VOLCANICA': 'ERUPCIÓN VOLCÁNICA',\n",
    "#     'CONTAMINACION': 'CONTAMINACION AMBIENTAL',\n",
    "#     'MAR DELEVA': 'MAR DE LEVA',\n",
    "#     'ACCIDENTE DE TRANSITO': 'ACCIDENTE TRANSPORTE TERRESTRE',\n",
    "#     'ACCIDENTE TERRESTRE': 'ACCIDENTE TRANSPORTE TERRESTRE',\n",
    "#     'INCENDIO DE RESIDUO VEGETAL': 'INCENDIO DE COBERTURA VEGETAL',\n",
    "#     'ACCIDENTE FLUVIAL': 'ACCIDENTE TRANSPORTE MARITIMO O FLUVIAL',\n",
    "#     'ACCIDENTE MARITIMO': 'ACCIDENTE TRANSPORTE MARITIMO O FLUVIAL'\n",
    "# }\n",
    "\n",
    "# # Reemplazar los valores en la columna \"TIPO DE EVENTO\" según el diccionario\n",
    "# df4['TIPO DE EVENTO'] = df4['TIPO DE EVENTO'].replace(reemplazos_unificacion)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "aea2476e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Guardo el df como procesamiento de los datos de tipos de evento\n",
    "\n",
    "# df4.to_csv('Rtado_prueba/df_TiposEvento.csv',index=False)\n",
    "# df4.to_excel('Rtado_prueba/df_TiposEvento.xlsx',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "63e1c85d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Filtro los tipos de evento con los que voy a trabajar originalmente que son :\n",
    "\n",
    "# #  'VENDAVAL' 'MOVIMIENTO EN MASA' 'INUNDACION' 'TORMENTA ELECTRICA' 'CRECIENTE SUBITA' 'AVENIDA TORRENCIAL'\n",
    "\n",
    "# #Creo una lista con los eventos:\n",
    "\n",
    "# eventos_filtro=['VENDAVAL' ,'MOVIMIENTO EN MASA', 'INUNDACION','TORMENTA ELECTRICA', 'CRECIENTE SUBITA', 'AVENIDA TORRENCIAL']\n",
    "\n",
    "# #se guardan los eventos de interés, en las fechas que se tienen (2001 a 2023)\n",
    "\n",
    "# df4_filtro=df4[df4['TIPO DE EVENTO'].isin(eventos_filtro)]\n",
    "\n",
    "# # Crear una copia explícita del DataFrame para evitar la advertencia\n",
    "# df4_filtro = df4_filtro.copy()\n",
    "\n",
    "# # Convertir la columna \"FECHA\" a formato de fecha\n",
    "# df4_filtro['FECHA'] = pd.to_datetime(df4_filtro['FECHA'], errors='coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "d77a623e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Selecciono el periodo que quiero trabajar, en este caso de 2001 a 2021\n",
    "# # Asegurarse de que la columna \"FECHA\" esté en formato de fecha\n",
    "# # Convertir la columna \"FECHA\" al formato de fecha, convirtiendo fechas no válidas a NaT\n",
    "\n",
    "# # Crear una copia del DataFrame original con el periodo de interés\n",
    "# df4_periodo2021 = df4_filtro[(df4_filtro['FECHA'].dt.year >= 2001) & (df4_filtro['FECHA'].dt.year <= 2021)].copy()\n",
    "\n",
    "\n",
    "# # Convertir la columna \"FECHA\" a formato de fecha\n",
    "# df4_periodo2021['FECHA'] = pd.to_datetime(df4_filtro['FECHA'], errors='coerce')\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "8949ecc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Para tener como alternativa también se guarda el dataframe que contiene los eventos de interés de 2001 a 2023\n",
    "\n",
    "# # Crear una copia del DataFrame original\n",
    "# df4_periodo2023 = df4_filtro[(df4_filtro['FECHA'].dt.year >= 2001) & (df4_filtro['FECHA'].dt.year <= 2023)].copy()\n",
    "\n",
    "# # Convertir la columna \"FECHA\" a formato de fecha\n",
    "# df4_periodo2023['FECHA'] = pd.to_datetime(df4_filtro['FECHA'], errors='coerce')\n",
    "\n",
    "# # Eliminar las filas donde la columna \"FECHA\" es NaT\n",
    "# df4_periodo2023 = df4_periodo2023.dropna(subset=['FECHA'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "36a263ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "#GUARDAMOS LOS DATAFRAMES\n",
    "\n",
    "# df4_periodo2021.to_csv('Rtado_prueba/desastres_2001_2021.csv',index=False)\n",
    "\n",
    "# df4_periodo2023.to_csv('Rtado_prueba/desastres_2001_2023.csv',index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "8b29fdd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Me faltó revisar que todos los códigos de municipios estuvieran completos\n",
    "# #Vuelvo a importar el archivo\n",
    "\n",
    "# df4_2023=pd.read_csv(\"Rtado_prueba/desastres_2001_2023.csv\", encoding='UTF-8')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "9a127da9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# #Busco datos vacíos en la columna CÓDIGO DANE DEL MUNICIPIO\n",
    "# # Filtrar las filas donde \"CÓDIGO DANE DEL MUNICIPIO\" está vacío o es nulo\n",
    "# filas_vacias = df4_2023[pd.isna(df4_2023['CÓDIGO DANE DEL MUNICIPIO'])]\n",
    "\n",
    "# filas_vacias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "057de3b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #municipios que tienen celdas de códigos como Nans:\n",
    "\n",
    "# mpios_vacios=filas_vacias['MUNICIPIO'].unique()\n",
    "# mpios_vacios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "5a9af90b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Reemplazo los valores del CÓDIGO DEL MUNICIPIO DANE NaNs por los correspondientes apoyandome en los códigos del DANE oficiales\n",
    "\n",
    "\n",
    "# # Lista de tuplas con el formato (Municipio, Departamento, Código DANE)\n",
    "# actualizaciones = [\n",
    "#     ('SAN LUIS DE PALENQUE', 'CASANARE', 85.325),\n",
    "#     ('EL PEÑOL', 'NARIÑO', 52.254),\n",
    "#     ('BUENAVISTA', 'CÓRDOBA', 23.079),\n",
    "#     ('BUENAVISTA', 'BOYACÁ', 15.109),\n",
    "#     ('BUENAVISTA', 'QUINDÍO', 63.111),\n",
    "#     ('BUENAVISTA','SUCRE',70.110),\n",
    "#     ('SAN PABLO', 'BOLÍVAR', 13.670),\n",
    "#     ('SAN PABLO', 'NARIÑO', 52.693)\n",
    "# ]\n",
    "\n",
    "# # Recorrer la lista y aplicar los cambios\n",
    "# for municipio, departamento, codigo in actualizaciones:\n",
    "#     df4_2023.loc[(df4_2023['MUNICIPIO'] == municipio) & \n",
    "#                         (df4_2023['DEPARTAMENTO'] == departamento), \n",
    "#                         'CÓDIGO DANE DEL MUNICIPIO'] = codigo\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "b5aee99e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Se crea una columna con los códigos del departamento\n",
    "\n",
    "# # Crear una nueva columna \"COD_DEP\"  que serían los códigos de departamento.\n",
    "#    #Uso la columna de código dane del municipio porque el número entero es el código del departamento\n",
    "# df4_2023['COD_DEP'] = np.floor(df4_2023['CÓDIGO DANE DEL MUNICIPIO']).astype(int)\n",
    "\n",
    "# #Y convierto los números a str para unificarlos con los códigos de shapefiles del DANE\n",
    "# # Convertir los valores de \"COD_DEP\" a cadenas de texto y asegurarse de que tengan 2 dígitos\n",
    "# df4_2023['COD_DEP'] = df4_2023['COD_DEP'].astype(str).str.zfill(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "dbdd2308",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #También creo una nueva columna del código del municipio sin el cod departamento para unificar formatos respecto a shapefiles DANE\n",
    "\n",
    "# # Crear la nueva columna \"COD_MUN\" extrayendo la parte después del punto\n",
    "# df4_2023['COD_MUN'] = df4_2023['CÓDIGO DANE DEL MUNICIPIO'].astype(str).str.split('.').str[1]\n",
    "\n",
    "# # Asegurarse de que todos los códigos tengan 3 dígitos, agregando ceros a la derecha si es necesario\n",
    "# df4_2023['COD_MUN'] = df4_2023['COD_MUN'].apply(lambda x: x.ljust(3, '0'))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "24bc9a51",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#  # Crear una copia del DataFrame original con el periodo de interés\n",
    "    \n",
    "#     #primero lo convierto a datetime a FECHA\n",
    "# #Convertir la columna \"FECHA\" a formato de fecha\n",
    "# df4_2023['FECHA'] = pd.to_datetime(df4_2023['FECHA'], errors='coerce')    \n",
    "\n",
    "# #Creo copia del dataframe para el periodo 2008-2020\n",
    "# df4_2021 = df4_2023[(df4_2023['FECHA'].dt.year >= 2001) & (df4_2023['FECHA'].dt.year <= 2021)].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "ba7c013d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #GUARDAMOS LOS DATAFRAMES\n",
    "\n",
    "# df4_2020.to_csv('Rtado_prueba/desastres_2001_2021.csv',index=False)\n",
    "# df4_2020.to_excel('Rtado_prueba/desastres_2001_2021.xlsx',index=False)\n",
    "# df4_2023.to_csv('Rtado_prueba/desastres_2001_2023.csv',index=False)\n",
    "# df4_2023.to_excel('Rtado_prueba/desastres_2001_2023.xlsx',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "7a7a4c6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Llamo el df creado anteriormente (df4_2023 y df4_2020)\n",
    "#  #llamo también los datos del shapefile de Mpios_Col_DANE_2023\n",
    "    \n",
    "# df5_2023=pd.read_csv(\"Rtado_prueba/desastres_2001_2023.csv\", encoding='UTF-8')\n",
    "# DANE=pd.read_csv(\"D:/Tesis_qgis/P_Col/Mpios_Col_DANE_2023.csv\", encoding='UTF-8')\n",
    "\n",
    "# #La idea es observar diferencias entre ellos para Unificar nombres/códigos y poder realizar las gráficas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "4db68c23",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Configuro la información para que tengan el mismo formato de códigos de municipio y departamento en ambos dfs\n",
    "\n",
    "# #Primero lo configuro en df5_2023 (información de desastres)------\n",
    "\n",
    "# #Configuro la info de DEPARTAMENTOS\n",
    "# # # Convertir los valores de \"COD_DEP\" a cadenas de texto y asegurarse de que tengan 2 dígitos\n",
    "# df5_2023['COD_DEP'] = df5_2023['COD_DEP'].astype(str).str.zfill(2)\n",
    "\n",
    "# #Configuro la info de MUNICIPIOS\n",
    "# # # Convertir los valores de \"COD_MUN\" a cadenas de texto y asegurarse de que tengan 3 dígitos\n",
    "# df5_2023['COD_MUN'] = df5_2023['COD_MUN'].astype(str).str.zfill(3)\n",
    "\n",
    "# #Creo una nueva columna que junte la info de COD_DEP y COD_MUN para tenerla en el mismo formato que DANE\n",
    "\n",
    "# df5_2023['COD_DEP_MUN']= df5_2023['COD_DEP'] + df5_2023['COD_MUN']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "138bd89e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Ahora configuro la información para DANE\n",
    "\n",
    "# #Configuro la info de DEPARTAMENTOS\n",
    "# # # Convertir los valores de \"dpto_ccdgo\" a cadenas de texto y asegurarse de que tengan 2 dígitos\n",
    "# DANE['dpto_ccdgo'] = DANE['dpto_ccdgo'].astype(str).str.zfill(2)\n",
    "\n",
    "# #Configuro la info de MUNICIPIOS\n",
    "# # # Convertir los valores de \"dpto_ccdgo\" a cadenas de texto y asegurarse de que tengan 3 dígitos\n",
    "# DANE['mpio_ccdgo'] = DANE['mpio_ccdgo'].astype(str).str.zfill(3)\n",
    "\n",
    "# #Configuro la info de DEPTOS + MPIOS (mpio_cdpmp)\n",
    "# DANE['mpio_cdpmp'] = DANE['mpio_cdpmp'].astype(str).str.zfill(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "2bfd9379",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Códigos que están en df5_2023 pero no en DANE: {'27086'}\n",
      "Códigos que están en DANE pero no en df5_2023: {'94888', '94885', '91669', '94883', '97511', '05664', '94887', '91460', '94886', '97777', '94884', '91430', '94343', '97666'}\n"
     ]
    }
   ],
   "source": [
    "# #Comparar las columnas de mpio_cdpmp en DANE y COD_DEP_MUN para ver diferencias\n",
    "\n",
    "# # Obtener los códigos únicos de la columna \"COD_DEP_MUN\" en df5_2023\n",
    "# codigos_df5_2023 = df5_2023['COD_DEP_MUN'].unique()\n",
    "\n",
    "# # Obtener los códigos únicos de la columna \"mpio_cdpmp\" en DANE\n",
    "# codigos_dane = DANE['mpio_cdpmp'].unique()\n",
    "\n",
    "# # Convertir los arrays a conjuntos para facilitar la comparación\n",
    "# set_df5_2023 = set(codigos_df5_2023)\n",
    "# set_dane = set(codigos_dane)\n",
    "\n",
    "# # Encontrar los códigos que están en df5_2023 pero no en DANE\n",
    "# codigos_faltantes_en_dane = set_df5_2023 - set_dane\n",
    "\n",
    "# # Encontrar los códigos que están en DANE pero no en df5_2023\n",
    "# codigos_faltantes_en_df5_2023 = set_dane - set_df5_2023\n",
    "\n",
    "# # Mostrar resultados\n",
    "# print(\"Códigos que están en df5_2023 pero no en DANE:\", codigos_faltantes_en_dane)\n",
    "# print(\"Códigos que están en DANE pero no en df5_2023:\", codigos_faltantes_en_df5_2023)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "8f7dcbe0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FECHA</th>\n",
       "      <th>DEPARTAMENTO</th>\n",
       "      <th>MUNICIPIO</th>\n",
       "      <th>TIPO DE EVENTO</th>\n",
       "      <th>DIVIPOLA</th>\n",
       "      <th>FALLECIDOS</th>\n",
       "      <th>HERIDOS</th>\n",
       "      <th>DESAPARECIDOS</th>\n",
       "      <th>AFECTADOS</th>\n",
       "      <th>FAMILIAS</th>\n",
       "      <th>VIVIENDAS DESTRUIDAS</th>\n",
       "      <th>VIVIENDAS AVERIADAS</th>\n",
       "      <th>CÓDIGO DANE DEL MUNICIPIO</th>\n",
       "      <th>COD_DEP</th>\n",
       "      <th>COD_MUN</th>\n",
       "      <th>COD_DEP_MUN</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>2001-04-19</td>\n",
       "      <td>CHOCÓ</td>\n",
       "      <td>BELÉN DE BAJIRA</td>\n",
       "      <td>VENDAVAL</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>180</td>\n",
       "      <td>36</td>\n",
       "      <td>0</td>\n",
       "      <td>36</td>\n",
       "      <td>27.086</td>\n",
       "      <td>27</td>\n",
       "      <td>086</td>\n",
       "      <td>27086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>506</th>\n",
       "      <td>2002-08-05</td>\n",
       "      <td>CHOCÓ</td>\n",
       "      <td>BELÉN DE BAJIRA</td>\n",
       "      <td>VENDAVAL</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>640</td>\n",
       "      <td>128</td>\n",
       "      <td>0</td>\n",
       "      <td>87</td>\n",
       "      <td>27.086</td>\n",
       "      <td>27</td>\n",
       "      <td>086</td>\n",
       "      <td>27086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1994</th>\n",
       "      <td>2005-05-19</td>\n",
       "      <td>CHOCÓ</td>\n",
       "      <td>BELÉN DE BAJIRA</td>\n",
       "      <td>INUNDACION</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4,600</td>\n",
       "      <td>920</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>27.086</td>\n",
       "      <td>27</td>\n",
       "      <td>086</td>\n",
       "      <td>27086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2001</th>\n",
       "      <td>2005-05-19</td>\n",
       "      <td>CHOCÓ</td>\n",
       "      <td>BELÉN DE BAJIRA</td>\n",
       "      <td>INUNDACION</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>27.086</td>\n",
       "      <td>27</td>\n",
       "      <td>086</td>\n",
       "      <td>27086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31105</th>\n",
       "      <td>2022-11-21</td>\n",
       "      <td>CHOCÓ</td>\n",
       "      <td>BELÉN DE BAJIRA</td>\n",
       "      <td>INUNDACION</td>\n",
       "      <td>27086</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7,912</td>\n",
       "      <td>1,978</td>\n",
       "      <td>0</td>\n",
       "      <td>894</td>\n",
       "      <td>27.086</td>\n",
       "      <td>27</td>\n",
       "      <td>086</td>\n",
       "      <td>27086</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           FECHA DEPARTAMENTO        MUNICIPIO TIPO DE EVENTO DIVIPOLA  \\\n",
       "33    2001-04-19        CHOCÓ  BELÉN DE BAJIRA       VENDAVAL        0   \n",
       "506   2002-08-05        CHOCÓ  BELÉN DE BAJIRA       VENDAVAL        0   \n",
       "1994  2005-05-19        CHOCÓ  BELÉN DE BAJIRA     INUNDACION        0   \n",
       "2001  2005-05-19        CHOCÓ  BELÉN DE BAJIRA     INUNDACION        0   \n",
       "31105 2022-11-21        CHOCÓ  BELÉN DE BAJIRA     INUNDACION    27086   \n",
       "\n",
       "      FALLECIDOS HERIDOS DESAPARECIDOS AFECTADOS FAMILIAS  \\\n",
       "33             0       0             0       180       36   \n",
       "506            0       0             0       640      128   \n",
       "1994           0       0             0     4,600      920   \n",
       "2001           0       0             0         0        0   \n",
       "31105          0       0             0     7,912    1,978   \n",
       "\n",
       "      VIVIENDAS DESTRUIDAS VIVIENDAS AVERIADAS  CÓDIGO DANE DEL MUNICIPIO  \\\n",
       "33                       0                  36                     27.086   \n",
       "506                      0                  87                     27.086   \n",
       "1994                     0                   0                     27.086   \n",
       "2001                     0                   0                     27.086   \n",
       "31105                    0                 894                     27.086   \n",
       "\n",
       "      COD_DEP COD_MUN COD_DEP_MUN  \n",
       "33         27     086       27086  \n",
       "506        27     086       27086  \n",
       "1994       27     086       27086  \n",
       "2001       27     086       27086  \n",
       "31105      27     086       27086  "
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Solo hay un municipio que está en desastres_2023 pero no en DANE y es BELÉN DE BAJIRÁ, que, no es mpio es corregimiento(o era hasta 2024, ya sí es mpio)\n",
    "#  #Los registros de BELÉN DE BAJIRÁ se anexan a los registros del municipio de riosucio en el CHOCÓ\n",
    "#   #COD_DEP_MUN de RIOSUCIO es: 27615 y el de BELÉN DE BAJIRÁ es 27086\n",
    "# belen_bajira= df5_2023[df5_2023['COD_DEP_MUN']=='27086']\n",
    "# belen_bajira"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "2c73e76b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Guardo dataframe para el periodo 2001-2021\n",
    "\n",
    "# # #Convertir la columna \"FECHA\" a formato de fecha\n",
    "# df5_2023['FECHA'] = pd.to_datetime(df5_2023['FECHA'], errors='coerce')    \n",
    "\n",
    "\n",
    "# # #Creo copia del dataframe para el periodo 2008-2020\n",
    "# df5_2021 = df5_2023[(df5_2023['FECHA'].dt.year >= 2001) & (df5_2023['FECHA'].dt.year <= 2021)].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "b13c26b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # #GUARDAMOS LOS DATAFRAMES\n",
    "\n",
    "# df5_2021.to_csv('Rtado_prueba/desastres_2001_2021_graf.csv',index=False)\n",
    "# df5_2023.to_csv('Rtado_prueba/desastres_2001_2023_graf.csv',index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e52cc4d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
