{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "c7aee9ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Este notebook tiene como objetivo graficar los desastres naturales por municipio/departamento de la información de desastres\n",
    " # procesada en el paso 1. Los resultados de este notebook se usan para graficar la distribución de los desastres naturales y\n",
    "   #... los sistemas convectivos de mesoescala"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "27352d0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Importamos librerías\n",
    "# import geopandas as gpd\n",
    "# import pandas as pd\n",
    "# import matplotlib.pyplot as plt\n",
    "# import numpy as np\n",
    "# from mpl_toolkits.axes_grid1.inset_locator import inset_axes\n",
    "# import fiona\n",
    "# import unidecode\n",
    "# import random\n",
    "# import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "66f00fc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Cargar el shapefile de DANE, Datos de municipio oficiales del portal\n",
    "# dane_shp = gpd.read_file(\"C:/Users/Miguel/Documents/P_Col/MGN2023_MPIO_POLITICO/MGN_ADM_MPIO_GRAFICO.shp\")\n",
    "\n",
    "# #Cargo shape de DANE por deptos\n",
    "# dane_shp_dep= gpd.read_file(\"C:/Users/Miguel/Documents/P_Col/MGN2023_DPTO_POLITICO/MGN_ADM_DPTO_POLITICO.shp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "8f90cb51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Cargar los datos de desastres procesadas en el paso 1 de control de calidad\n",
    "# desastres_2023= pd.read_csv(\"Rtado_prueba/desastres_2001_2023_graf.csv\", encoding='UTF-8',low_memory=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "2f637e72-385f-42ad-9a90-1727bd8a0795",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Para el procedimiento final se eliminan los casos de vendaval y tormenta eléctrica\n",
    "\n",
    "# # Lista de eventos a eliminar\n",
    "# eventos_excluir = ['VENDAVAL', 'TORMENTA ELÉCTRICA','TORMENTA ELECTRICA']\n",
    "\n",
    "# desastres_2023= desastres_2023[~desastres_2023['TIPO DE EVENTO'].isin(eventos_excluir)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "bda4d717",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Defino un nuevo df con periodo de 2001 a 2021 para el análisis con MCS\n",
    "#  #Este df se va a diferenciar porque tiene sufijo _2021\n",
    "\n",
    "#  #Convertir la columna \"FECHA\" a formato de fecha\n",
    "# desastres_2023['FECHA'] = pd.to_datetime(desastres_2023['FECHA'], errors='coerce')    \n",
    "\n",
    "# # #Creo copia del dataframe para el periodo 2001-2021\n",
    "# desastres_2021 = desastres_2023[(desastres_2023['FECHA'].dt.year >= 2001) & (desastres_2023['FECHA'].dt.year <= 2021)].copy()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "d7e85082",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Proceso la información para que COD_MUN Y COD_DEP tengan el mismo formato que el shape\n",
    "# #Configuro la info de DEPARTAMENTOS\n",
    "# # # Convertir los valores de \"COD_DEP\" a cadenas de texto y asegurarse de que tengan 2 dígitos\n",
    "# desastres_2023['COD_DEP'] = desastres_2023['COD_DEP'].astype(str).str.zfill(2)\n",
    "# desastres_2021['COD_DEP'] = desastres_2021['COD_DEP'].astype(str).str.zfill(2)\n",
    "\n",
    "# #Configuro la info de MUNICIPIOS\n",
    "# # # Convertir los valores de \"COD_MUN\" a cadenas de texto y asegurarse de que tengan 3 dígitos\n",
    "# desastres_2023['COD_MUN'] = desastres_2023['COD_MUN'].astype(str).str.zfill(3)\n",
    "# desastres_2021['COD_MUN'] = desastres_2021['COD_MUN'].astype(str).str.zfill(3)\n",
    "\n",
    "# #Configuro info de COD_DEP_MUN\n",
    "\n",
    "# desastres_2023['COD_DEP_MUN'] = desastres_2023['COD_DEP_MUN'].astype(str).str.zfill(5)\n",
    "# desastres_2021['COD_DEP_MUN'] = desastres_2021['COD_DEP_MUN'].astype(str).str.zfill(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "dde2315e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Códigos que están en desastres_2021 pero no en DANE: {'27086'}\n",
      "Códigos que están en DANE pero no en desastres_2021: {'91460', '97777', '05664', '94883', '94885', '94888', '97511', '70230', '94884', '91430', '94886', '94343', '97889', '94887', '70702', '91669', '97666'}\n"
     ]
    }
   ],
   "source": [
    "# #para comparación \n",
    "# #Comparo los municipios que no están en df de desastres y sí en el gdf del dane\n",
    "# # Obtener los códigos únicos de la columna \"COD_DEP_MUN\" en desastres_2023\n",
    "# cod_2023 = desastres_2021['COD_DEP_MUN'].unique()\n",
    "\n",
    "# # Obtener los códigos únicos de la columna \"mpio_cdpmp\" en DANE\n",
    "# codigos_dane = dane_shp['mpio_cdpmp'].unique()\n",
    "\n",
    "# # Convertir los arrays a conjuntos para facilitar la comparación\n",
    "# set_desastres_2023 = set(cod_2023)\n",
    "# set_dane = set(codigos_dane)\n",
    "\n",
    "# # Encontrar los códigos que están en desastres_2023 pero no en DANE\n",
    "# codigos_faltantes_en_dane = set_desastres_2023 - set_dane\n",
    "\n",
    "# # Encontrar los códigos que están en DANE pero no en desastres_2023\n",
    "# codigos_faltantes_en_desastres_2023 = set_dane - set_desastres_2023\n",
    "\n",
    "# # Mostrar resultados\n",
    "# print(\"Códigos que están en desastres_2021 pero no en DANE:\", codigos_faltantes_en_dane)\n",
    "print(\"Códigos que están en DANE pero no en desastres_2021:\", codigos_faltantes_en_desastres_2023)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "195423c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Miguel\\AppData\\Local\\Temp\\ipykernel_5720\\11239033.py:11: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '27.615' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  desastres_2023.loc[\n",
      "C:\\Users\\Miguel\\AppData\\Local\\Temp\\ipykernel_5720\\11239033.py:25: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '27.615' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  desastres_2021.loc[\n"
     ]
    }
   ],
   "source": [
    "# # Ahora corrijo la información de BELEN DE BAJIRÁ (27086) que es el único municipio erroneo en desastres\n",
    "#   #Este era un corregimiento hasta 2023, entonces los registros los pongo a nombre de RIOSUCIO, CHOCÓ\n",
    "    \n",
    "# # Filtrar los registros de BELÉN DE BAJIRÁ en el departamento de Chocó (COD_DEP = 27)\n",
    "# desastres_2023.loc[\n",
    "#     (desastres_2023['MUNICIPIO'] == 'BELÉN DE BAJIRA') & (desastres_2023['COD_DEP'] == 27),\n",
    "#     'MUNICIPIO'\n",
    "# ] = 'RIOSUCIO'\n",
    "\n",
    "# # Actualizar las columnas relacionadas SOLO para los registros del municipio de BELÉN DE BAJIRA en el departamento de CHOCÓ\n",
    "# desastres_2023.loc[\n",
    "#     (desastres_2023['MUNICIPIO'] == 'RIOSUCIO') & (desastres_2023['COD_DEP'] == 27), \n",
    "#     ['DIVIPOLA', 'CÓDIGO DANE DEL MUNICIPIO', 'COD_DEP', 'COD_MUN', 'COD_DEP_MUN']\n",
    "# ] = [27615, '27.615', '27', '615', '27615']\n",
    "\n",
    "\n",
    "# #Hacemos lo mismo para el df 2021\n",
    "\n",
    "# desastres_2021.loc[\n",
    "#     (desastres_2021['MUNICIPIO'] == 'BELÉN DE BAJIRA') & (desastres_2021['COD_DEP'] == '27'),\n",
    "#     'MUNICIPIO'\n",
    "# ] = 'RIOSUCIO'\n",
    "\n",
    "# # Actualizar las columnas relacionadas SOLO para los registros del municipio de BELÉN DE BAJIRA en el departamento de CHOCÓ\n",
    "# desastres_2021.loc[\n",
    "#     (desastres_2021['MUNICIPIO'] == 'RIOSUCIO') & (desastres_2021['COD_DEP'] == '27'), \n",
    "#     ['DIVIPOLA', 'CÓDIGO DANE DEL MUNICIPIO', 'COD_DEP', 'COD_MUN', 'COD_DEP_MUN']\n",
    "# ] = [27615, '27.615', '27', '615', '27615']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "100d637f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Miguel\\AppData\\Local\\Temp\\ipykernel_5720\\1512794637.py:23: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  desastres_2023[col].fillna(0, inplace=True)\n",
      "C:\\Users\\Miguel\\AppData\\Local\\Temp\\ipykernel_5720\\1512794637.py:24: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  desastres_2021[col].fillna(0, inplace=True)\n"
     ]
    }
   ],
   "source": [
    "# #Quiero realizar gráficas de las diferentes columnas entonces se procesan todas acá\n",
    "\n",
    "# #Para las columnas se identifica un error y es que hay celdas donde hay comas para representar miles (ejm: 1,890 - 1,239)\n",
    "#  #Se corrigen las celdas donde se encuentra este error. Se corrigen Nans y se convierten a enteros\n",
    "    \n",
    "#     # primero se guardan las columnas a procesar\n",
    "# cols_procesar = ['COD_DEP', 'COD_DEP_MUN','FALLECIDOS', 'HERIDOS', 'DESAPARECIDOS', 'AFECTADOS', \n",
    "#                    'FAMILIAS', 'VIVIENDAS DESTRUIDAS', 'VIVIENDAS AVERIADAS']\n",
    "\n",
    "# # Se reemplazan las comas en las columnas\n",
    "# for col in cols_procesar:\n",
    "#     desastres_2023[col] = desastres_2023[col].str.replace(',', '')\n",
    "#     desastres_2021[col] = desastres_2021[col].str.replace(',', '')\n",
    "\n",
    "# # Reemplazar espacios en blanco y caracteres no numéricos por NaN y convertir a numérico\n",
    "# for col in cols_procesar:\n",
    "#     desastres_2023[col] = pd.to_numeric(desastres_2023[col].str.strip(), errors='coerce')\n",
    "#     desastres_2021[col] = pd.to_numeric(desastres_2021[col].str.strip(), errors='coerce')\n",
    "\n",
    "\n",
    "# #  Rellenar valores NaN con 0\n",
    "# for col in cols_procesar:\n",
    "#     desastres_2023[col].fillna(0, inplace=True)\n",
    "#     desastres_2021[col].fillna(0, inplace=True)\n",
    "\n",
    "# # Paso 4: Convertir las columnas a enteros\n",
    "# for col in cols_procesar:\n",
    "#     desastres_2023[col] = desastres_2023[col].astype(int)\n",
    "#     desastres_2021[col] = desastres_2021[col].astype(int)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "1c93806b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Después de procesar agrego los datos de HERIDOS, FALLECIDOS y AFECTADOS\n",
    "# # Agrupar los datos por COD_DEP y COD_DEP_MUN (para municipios) para sumar HERIDOS, FALLECIDOs, afectados...\n",
    "# #PARA MUNICIPIOS\n",
    "\n",
    "# eventos_mpio = desastres_2023.groupby(['COD_DEP', 'COD_DEP_MUN']).agg(\n",
    "#     EVENT_MUN=('COD_DEP_MUN', 'size'),\n",
    "#     HERIDOS=('HERIDOS', 'sum'),\n",
    "#     FALLECIDOS=('FALLECIDOS', 'sum'),\n",
    "#     AFECTADOS=('AFECTADOS', 'sum'),\n",
    "#     DESAPARE=('DESAPARECIDOS', 'sum'),\n",
    "#     FAMILIAS=('FAMILIAS', 'sum'),\n",
    "#     VIV_DESTRU=('VIVIENDAS DESTRUIDAS', 'sum'),\n",
    "#     VIV_AVER=('VIVIENDAS AVERIADAS', 'sum')\n",
    "# ).reset_index()\n",
    "\n",
    "# eventos_mpio2 = desastres_2021.groupby(['COD_DEP', 'COD_DEP_MUN']).agg(\n",
    "#     EVENT_MUN=('COD_DEP_MUN', 'size'),\n",
    "#     HERIDOS=('HERIDOS', 'sum'),\n",
    "#     FALLECIDOS=('FALLECIDOS', 'sum'),\n",
    "#     AFECTADOS=('AFECTADOS', 'sum'),\n",
    "#     DESAPARE=('DESAPARECIDOS', 'sum'),\n",
    "#     FAMILIAS=('FAMILIAS', 'sum'),\n",
    "#     VIV_DESTRU=('VIVIENDAS DESTRUIDAS', 'sum'),\n",
    "#     VIV_AVER=('VIVIENDAS AVERIADAS', 'sum')\n",
    "# ).reset_index()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "ba2f8c9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #OBTENGO EL TIPO DE EVENTO MÁS FRECUENTE PARA MUNICIPIOS y con más fallecidos /afectados\n",
    "\n",
    "# #Para el df de 2023 MUNICIPIOS:\n",
    "\n",
    "# #Primero obtengo el evento más frecuente\n",
    "\n",
    "# # Obtener el tipo de evento más frecuente por municipio\n",
    "# evento_mas_frecuente = desastres_2023.groupby(['COD_DEP_MUN', 'TIPO DE EVENTO']).size().reset_index(name='EVENTO_COUNT')\n",
    "\n",
    "# # Seleccionar el tipo de evento con mayor frecuencia en cada municipio\n",
    "# evento_mas_frecuente = evento_mas_frecuente.loc[evento_mas_frecuente.groupby('COD_DEP_MUN')['EVENTO_COUNT'].idxmax()]\n",
    "\n",
    "# # Renombrar la columna para claridad\n",
    "# evento_mas_frecuente = evento_mas_frecuente[['COD_DEP_MUN', 'TIPO DE EVENTO']].rename(columns={'TIPO DE EVENTO': 'FRECUENTE'})\n",
    "\n",
    "\n",
    "# #obtengo tipo de evento con más fallecidos y afectados\n",
    "\n",
    "# # Agrupar y sumar afectados y fallecidos por municipio y tipo de evento\n",
    "# eventos_afectados_fallecidos = desastres_2023.groupby(['COD_DEP_MUN', 'TIPO DE EVENTO']).agg({\n",
    "#     'AFECTADOS': 'sum',\n",
    "#     'FALLECIDOS': 'sum'\n",
    "# }).reset_index()\n",
    "\n",
    "# # Obtener el tipo de evento que generó más afectados\n",
    "# evento_mas_afectados = eventos_afectados_fallecidos.loc[eventos_afectados_fallecidos.groupby('COD_DEP_MUN')['AFECTADOS'].idxmax()]\n",
    "# evento_mas_afectados = evento_mas_afectados[['COD_DEP_MUN', 'TIPO DE EVENTO']].rename(columns={'TIPO DE EVENTO': 'MAS_AFECTA'})\n",
    "\n",
    "# # Obtener el tipo de evento que generó más fallecidos\n",
    "# evento_mas_fallecidos = eventos_afectados_fallecidos.loc[eventos_afectados_fallecidos.groupby('COD_DEP_MUN')['FALLECIDOS'].idxmax()]\n",
    "# evento_mas_fallecidos = evento_mas_fallecidos[['COD_DEP_MUN', 'TIPO DE EVENTO']].rename(columns={'TIPO DE EVENTO': 'MAS_FALLECI'})\n",
    "\n",
    "# # Combinar los resultados en un solo DataFrame\n",
    "# resultados_tipos_eventos = evento_mas_frecuente.merge(evento_mas_afectados, on='COD_DEP_MUN', how='left')\n",
    "# resultados_tipos_eventos = resultados_tipos_eventos.merge(evento_mas_fallecidos, on='COD_DEP_MUN', how='left')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "175bebcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Combino resultados de tipos de evento (más frecuente y fallecidos afectados) y datos de núm de eventos, fallecidos...\n",
    "# #para df_2023 MUNICIPIOS\n",
    "\n",
    "# eventos_mpio=eventos_mpio.merge(resultados_tipos_eventos,on='COD_DEP_MUN', how='left')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "f5db920e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #OBTENGO EL TIPO DE EVENTO MÁS FRECUENTE PARA MUNICIPIOS y con más fallecidos /afectados\n",
    "\n",
    "# #Para el df de 2021:\n",
    "\n",
    "# #Primero obtengo el evento más frecuente\n",
    "\n",
    "# # Obtener el tipo de evento más frecuente por municipio\n",
    "# evento_mas_frecuente2 = desastres_2021.groupby(['COD_DEP_MUN', 'TIPO DE EVENTO']).size().reset_index(name='EVENTO_COUNT')\n",
    "\n",
    "# # Seleccionar el tipo de evento con mayor frecuencia en cada municipio\n",
    "# evento_mas_frecuente2 = evento_mas_frecuente2.loc[evento_mas_frecuente2.groupby('COD_DEP_MUN')['EVENTO_COUNT'].idxmax()]\n",
    "\n",
    "# # Renombrar la columna para claridad\n",
    "# evento_mas_frecuente2 = evento_mas_frecuente2[['COD_DEP_MUN', 'TIPO DE EVENTO']].rename(columns={'TIPO DE EVENTO': 'FRECUENTE'})\n",
    "\n",
    "\n",
    "# #obtengo tipo de evento con más fallecidos y afectados\n",
    "\n",
    "# # Agrupar y sumar afectados y fallecidos por municipio y tipo de evento\n",
    "# eventos_afectados_fallecidos2 = desastres_2021.groupby(['COD_DEP_MUN', 'TIPO DE EVENTO']).agg({\n",
    "#     'AFECTADOS': 'sum',\n",
    "#     'FALLECIDOS': 'sum'\n",
    "# }).reset_index()\n",
    "\n",
    "# # Obtener el tipo de evento que generó más afectados\n",
    "# evento_mas_afectados2 = eventos_afectados_fallecidos2.loc[eventos_afectados_fallecidos2.groupby('COD_DEP_MUN')['AFECTADOS'].idxmax()]\n",
    "# evento_mas_afectados2 = evento_mas_afectados2[['COD_DEP_MUN', 'TIPO DE EVENTO']].rename(columns={'TIPO DE EVENTO': 'MAS_AFECTA'})\n",
    "\n",
    "# # Obtener el tipo de evento que generó más fallecidos\n",
    "# evento_mas_fallecidos2 = eventos_afectados_fallecidos2.loc[eventos_afectados_fallecidos2.groupby('COD_DEP_MUN')['FALLECIDOS'].idxmax()]\n",
    "# evento_mas_fallecidos2 = evento_mas_fallecidos2[['COD_DEP_MUN', 'TIPO DE EVENTO']].rename(columns={'TIPO DE EVENTO': 'MAS_FALLECI'})\n",
    "\n",
    "# # Combinar los resultados en un solo DataFrame\n",
    "# resultados_tipos_eventos2 = evento_mas_frecuente2.merge(evento_mas_afectados2, on='COD_DEP_MUN', how='left')\n",
    "# resultados_tipos_eventos2 = resultados_tipos_eventos2.merge(evento_mas_fallecidos2, on='COD_DEP_MUN', how='left')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "0f63d7fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Combino resultados de tipos de evento (más frecuente y fallecidos afectados) y datos de núm de eventos, fallecidos...\n",
    "# #para df_2021 MUNICIPIOS\n",
    "\n",
    "# eventos_mpio2=eventos_mpio2.merge(resultados_tipos_eventos2,on='COD_DEP_MUN', how='left')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "dfe0f4bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #PARA DEPARTAMENTOS\n",
    "# #Para realizar mapas por departamento agrupo por departamentos : COD_DEP\n",
    "#   #Realizo el proceso anterior pero para deptos\n",
    "\n",
    "# eventos_depto=desastres_2023.groupby(['COD_DEP']).agg(\n",
    "#     EVENT_DPTO=('COD_DEP', 'size'),\n",
    "#     HERIDOS=('HERIDOS', 'sum'),\n",
    "#     FALLECIDOS=('FALLECIDOS', 'sum'),\n",
    "#     AFECTADOS=('AFECTADOS', 'sum'),\n",
    "#     DESAPARE=('DESAPARECIDOS', 'sum'),\n",
    "#     FAMILIAS=('FAMILIAS', 'sum'),\n",
    "#     VIV_DESTRU=('VIVIENDAS DESTRUIDAS', 'sum'),\n",
    "#     VIV_AVER=('VIVIENDAS AVERIADAS', 'sum')\n",
    "# ).reset_index()\n",
    "\n",
    "# eventos_depto2 = desastres_2021.groupby(['COD_DEP']).agg(\n",
    "#     EVENT_DPTO=('COD_DEP', 'size'),\n",
    "#     HERIDOS=('HERIDOS', 'sum'),\n",
    "#     FALLECIDOS=('FALLECIDOS', 'sum'),\n",
    "#     AFECTADOS=('AFECTADOS', 'sum'),\n",
    "#     DESAPARE=('DESAPARECIDOS', 'sum'),\n",
    "#     FAMILIAS=('FAMILIAS', 'sum'),\n",
    "#     VIV_DESTRU=('VIVIENDAS DESTRUIDAS', 'sum'),\n",
    "#     VIV_AVER=('VIVIENDAS AVERIADAS', 'sum')\n",
    "# ).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "040ad327",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #OBTENGO EL TIPO DE EVENTO MÁS FRECUENTE PARA DEPARTAMENTOS y con más fallecidos /afectados\n",
    "\n",
    "# #Para el df de 2023 DEPARTAMENTOS:\n",
    "\n",
    "# # Obtener el tipo de evento más frecuente por departamento\n",
    "# evento_mas_frecuente_dpt = desastres_2023.groupby(['COD_DEP', 'TIPO DE EVENTO']).size().reset_index(name='EVENTO_COUNT')\n",
    "\n",
    "# # Seleccionar el tipo de evento con mayor frecuencia en cada departamento\n",
    "# evento_mas_frecuente_dpt = evento_mas_frecuente_dpt.loc[evento_mas_frecuente_dpt.groupby('COD_DEP')['EVENTO_COUNT'].idxmax()]\n",
    "\n",
    "# # Renombrar la columna para claridad\n",
    "# evento_mas_frecuente_dpt = evento_mas_frecuente_dpt[['COD_DEP', 'TIPO DE EVENTO']].rename(columns={'TIPO DE EVENTO': 'FRECUENTE'})\n",
    "\n",
    "# # Agrupar y sumar afectados y fallecidos por departamento y tipo de evento\n",
    "# eventos_afectados_fallecidos_dpt = desastres_2023.groupby(['COD_DEP', 'TIPO DE EVENTO']).agg({\n",
    "#     'AFECTADOS': 'sum',\n",
    "#     'FALLECIDOS': 'sum'\n",
    "# }).reset_index()\n",
    "\n",
    "# # Obtener el tipo de evento que generó más afectados\n",
    "# evento_mas_afectados_dpt = eventos_afectados_fallecidos_dpt.loc[eventos_afectados_fallecidos_dpt.groupby('COD_DEP')['AFECTADOS'].idxmax()]\n",
    "# evento_mas_afectados_dpt = evento_mas_afectados_dpt[['COD_DEP', 'TIPO DE EVENTO']].rename(columns={'TIPO DE EVENTO': 'MAS_AFECTA'})\n",
    "\n",
    "# # Obtener el tipo de evento que generó más fallecidos\n",
    "# evento_mas_fallecidos_dpt = eventos_afectados_fallecidos_dpt.loc[eventos_afectados_fallecidos_dpt.groupby('COD_DEP')['FALLECIDOS'].idxmax()]\n",
    "# evento_mas_fallecidos_dpt = evento_mas_fallecidos_dpt[['COD_DEP', 'TIPO DE EVENTO']].rename(columns={'TIPO DE EVENTO': 'MAS_FALLECI'})\n",
    "\n",
    "# # Combinar los resultados en un solo DataFrame\n",
    "# resultados_tipos_eventos_dpt = evento_mas_frecuente_dpt.merge(evento_mas_afectados_dpt, on='COD_DEP', how='left')\n",
    "# resultados_tipos_eventos_dpt = resultados_tipos_eventos_dpt.merge(evento_mas_fallecidos_dpt, on='COD_DEP', how='left')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "6b541dc0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# #Combino resultados de tipos de evento (más frecuente y fallecidos afectados) y datos de núm de eventos, fallecidos...\n",
    "# #para df_2023 DEPARTAMENTOS\n",
    "\n",
    "# eventos_depto=eventos_depto.merge(resultados_tipos_eventos_dpt,on='COD_DEP', how='left')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "666e06b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #OBTENGO EL TIPO DE EVENTO MÁS FRECUENTE PARA DEPARTAMENTOS y con más fallecidos /afectados\n",
    "\n",
    "# #Para el df de 2021 DEPARTAMENTOS:\n",
    "\n",
    "# # Obtener el tipo de evento más frecuente por departamento\n",
    "# evento_mas_frecuente_dpt2 = desastres_2021.groupby(['COD_DEP', 'TIPO DE EVENTO']).size().reset_index(name='EVENTO_COUNT')\n",
    "\n",
    "# # Seleccionar el tipo de evento con mayor frecuencia en cada departamento\n",
    "# evento_mas_frecuente_dpt2 = evento_mas_frecuente_dpt2.loc[evento_mas_frecuente_dpt2.groupby('COD_DEP')['EVENTO_COUNT'].idxmax()]\n",
    "\n",
    "# # Renombrar la columna para claridad\n",
    "# evento_mas_frecuente_dpt2 = evento_mas_frecuente_dpt2[['COD_DEP', 'TIPO DE EVENTO']].rename(columns={'TIPO DE EVENTO': 'FRECUENTE'})\n",
    "\n",
    "# # Agrupar y sumar afectados y fallecidos por departamento y tipo de evento\n",
    "# eventos_afectados_fallecidos_dpt2 = desastres_2021.groupby(['COD_DEP', 'TIPO DE EVENTO']).agg({\n",
    "#     'AFECTADOS': 'sum',\n",
    "#     'FALLECIDOS': 'sum'\n",
    "# }).reset_index()\n",
    "\n",
    "# # Obtener el tipo de evento que generó más afectados\n",
    "# evento_mas_afectados_dpt2 = eventos_afectados_fallecidos_dpt2.loc[eventos_afectados_fallecidos_dpt2.groupby('COD_DEP')['AFECTADOS'].idxmax()]\n",
    "# evento_mas_afectados_dpt2 = evento_mas_afectados_dpt2[['COD_DEP', 'TIPO DE EVENTO']].rename(columns={'TIPO DE EVENTO': 'MAS_AFECTA'})\n",
    "\n",
    "# # Obtener el tipo de evento que generó más fallecidos\n",
    "# evento_mas_fallecidos_dpt2 = eventos_afectados_fallecidos_dpt2.loc[eventos_afectados_fallecidos_dpt2.groupby('COD_DEP')['FALLECIDOS'].idxmax()]\n",
    "# evento_mas_fallecidos_dpt2 = evento_mas_fallecidos_dpt2[['COD_DEP', 'TIPO DE EVENTO']].rename(columns={'TIPO DE EVENTO': 'MAS_FALLECI'})\n",
    "\n",
    "# # Combinar los resultados en un solo DataFrame\n",
    "# resultados_tipos_eventos_dpt2 = evento_mas_frecuente_dpt2.merge(evento_mas_afectados_dpt2, on='COD_DEP', how='left')\n",
    "# resultados_tipos_eventos_dpt2 = resultados_tipos_eventos_dpt2.merge(evento_mas_fallecidos_dpt2, on='COD_DEP', how='left')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "29c281ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Combino resultados de tipos de evento (más frecuente y fallecidos afectados) y datos de núm de eventos, fallecidos...\n",
    "#para df_2023 DEPARTAMENTOS\n",
    "\n",
    "# eventos_depto2=eventos_depto2.merge(resultados_tipos_eventos_dpt2,on='COD_DEP', how='left')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "2365baee",
   "metadata": {},
   "outputs": [],
   "source": [
    "#agrego los municipios que no están en el df de desastres a eventos_mpio para poder graficar todos los mpios del país\n",
    " #Los agrego con todos los registros en 0 (FALLECIDOS, AFECTADOS,etc...)\n",
    "    \n",
    "# #En este código agrego el df de 2023\n",
    "\n",
    "\n",
    "# municipios_a_agregar1 = {'97777', '94883', '94343', '91430', '94885', '97511', '94888', '94887', '94884', '97666', '94886', '91669', '05664', '91460'}\n",
    "\n",
    "# # Crear un DataFrame con las nuevas filas\n",
    "# nuevas_filas1 = pd.DataFrame({\n",
    "#     'COD_DEP_MUN': list(municipios_a_agregar1),\n",
    "#     'COD_DEP': [str(mun)[:2] for mun in municipios_a_agregar1],\n",
    "#     'EVENT_MUN': 0,\n",
    "#     'HERIDOS': 0,\n",
    "#     'FALLECIDOS': 0,\n",
    "#     'AFECTADOS': 0,\n",
    "#     'DESAPARE': 0,\n",
    "#     'FAMILIAS': 0,\n",
    "#     'VIV_DESTRU': 0,\n",
    "#     'VIV_AVER': 0,\n",
    "#     'FRECUENTE': 'SIN_INFO',\n",
    "#     'MAS_AFECTA': 'SIN_INFO',\n",
    "#     'MAS_FALLECI':'SIN_INFO'\n",
    "    \n",
    "# })\n",
    "\n",
    "# # llevo a entero 'COD_DEP_MUN' y 'COD_DEP' \n",
    "# nuevas_filas1['COD_DEP_MUN'] = nuevas_filas1['COD_DEP_MUN'].astype(int)\n",
    "# nuevas_filas1['COD_DEP'] = nuevas_filas1['COD_DEP'].astype(int)\n",
    "\n",
    "# # Concatenar las nuevas filas al DataFrame original\n",
    "# eventos_mpio = pd.concat([eventos_mpio, nuevas_filas1], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "9376665b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #agrego los municipios que no están en el df de desastres a eventos_mpio para poder graficar todos los mpios del país\n",
    "#  #Los agrego con todos los registros en 0 (FALLECIDOS, AFECTADOS,etc...)\n",
    "    \n",
    "# #En este código agrego el df de 2021\n",
    "\n",
    "# municipios_a_agregar =  {'91669', '97889', '94886', '91430', '05664', '94888', '94343', '91460', '94883', '94884', '97777', '94887', '97511', '94885', '97666'}\n",
    "# # Crear un DataFrame con las nuevas filas\n",
    "# nuevas_filas = pd.DataFrame({\n",
    "#     'COD_DEP_MUN': list(municipios_a_agregar),\n",
    "#     'COD_DEP': [str(mun)[:2] for mun in municipios_a_agregar],\n",
    "#     'EVENT_MUN': 0,\n",
    "#     'HERIDOS': 0,\n",
    "#     'FALLECIDOS': 0,\n",
    "#     'AFECTADOS': 0,\n",
    "#     'DESAPARE': 0,\n",
    "#     'FAMILIAS': 0,\n",
    "#     'VIV_DESTRU': 0,\n",
    "#     'VIV_AVER': 0,\n",
    "#     'FRECUENTE': 'SIN_INFO',\n",
    "#     'MAS_AFECTA': 'SIN_INFO',\n",
    "#     'MAS_FALLECI':'SIN_INFO'\n",
    "    \n",
    "# })\n",
    "\n",
    "# # llevo a entero 'COD_DEP_MUN' y 'COD_DEP' \n",
    "# nuevas_filas['COD_DEP_MUN'] = nuevas_filas['COD_DEP_MUN'].astype(int)\n",
    "# nuevas_filas['COD_DEP'] = nuevas_filas['COD_DEP'].astype(int)\n",
    "\n",
    "# # Concatenar las nuevas filas al DataFrame original\n",
    "# eventos_mpio2 = pd.concat([eventos_mpio2, nuevas_filas], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "17ee535f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convierto los códigos del DANE a numero para poder hacer un merge con el df de desastres \n",
    "\n",
    "# #Shape de municipios\n",
    "# dane_shp['dpto_ccdgo'] = dane_shp['dpto_ccdgo'].astype(int)\n",
    "# dane_shp['mpio_cdpmp'] = dane_shp['mpio_cdpmp'].astype(int)\n",
    "\n",
    "# #Shape Deptos\n",
    "# dane_shp_dep['dpto_ccdgo'] = dane_shp_dep['dpto_ccdgo'].astype(int)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "4085e9a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Realizo un merge entre el shape DANE y los desatres para poder graficar MUNICIPIOS\n",
    "\n",
    "# mapa_eventos = dane_shp.merge(eventos_mpio, left_on=['dpto_ccdgo', 'mpio_cdpmp'], right_on=['COD_DEP', 'COD_DEP_MUN'], how='left')\n",
    "\n",
    "# mapa_eventos2 = dane_shp.merge(eventos_mpio2, left_on=['dpto_ccdgo', 'mpio_cdpmp'], right_on=['COD_DEP', 'COD_DEP_MUN'], how='left')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "c339f580",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Realizo un merge entre el shape DANE y los desatres para poder graficar DEPARTAMENTOS\n",
    "\n",
    "# dpto_eventos = dane_shp_dep.merge(eventos_depto, left_on=['dpto_ccdgo'], right_on=['COD_DEP'], how='left')\n",
    "\n",
    "# dpto_eventos2 = dane_shp_dep.merge(eventos_depto2, left_on=['dpto_ccdgo'], right_on=['COD_DEP'], how='left')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "85a0f129",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Hago una copia de dpto_eventos DEPARTAMENTO, lo convierto a shapefile si no está y lo exporto\n",
    "\n",
    "# #copio df de mapa_eventos (num eventos por mpio, fallecidos...)\n",
    "# Recuento_dptos2023=dpto_eventos.copy()\n",
    "# Recuento_dptos2021=dpto_eventos2.copy()\n",
    "\n",
    "# # #Asegurarse de que sea un Geodataframe\n",
    "# Recuento_dptos2023 = gpd.GeoDataFrame(Recuento_dptos2023, geometry='geometry')\n",
    "# Recuento_dptos2021 = gpd.GeoDataFrame(Recuento_dptos2021, geometry='geometry')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "0e02685d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Hago una copia de mapa_eventos MUNICIPIO, lo convierto a shapefile si no está y lo exporto\n",
    "\n",
    "# #copio df de mapa_eventos (num eventos por mpio, fallecidos...)\n",
    "# Recuento_mpios2023=mapa_eventos.copy()\n",
    "# Recuento_mpios2021=mapa_eventos2.copy()\n",
    "\n",
    "# # #Asegurarse de que sea un Geodataframe\n",
    "# Recuento_mpios2023 = gpd.GeoDataFrame(Recuento_mpios2023, geometry='geometry')\n",
    "# Recuento_mpios2021 = gpd.GeoDataFrame(Recuento_mpios2021, geometry='geometry')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "99273501",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # # # # #Exporto los geodataframes de departamentos:\n",
    "\n",
    "# Recuento_dptos2023.to_file(\"D:/Tesis_qgis/P_Col/info_desastres_py/Recuento_dptos2023\", driver='ESRI Shapefile')\n",
    "# Recuento_dptos2021.to_file(\"D:/Tesis_qgis/P_Col/info_desastres_py/Recuento_dptos2021\", driver='ESRI Shapefile')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "5b3fa048",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# # # # # #Exporto los geodataframes de municipios:\n",
    "# Recuento_mpios2023.to_file(\"D:/Tesis_qgis/P_Col/info_desastres_py/Recuento_mpios2023\", driver='ESRI Shapefile')\n",
    "# Recuento_mpios2021.to_file(\"D:/Tesis_qgis/P_Col/info_desastres_py/Recuento_mpios2021\", driver='ESRI Shapefile')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "130295ab-4b80-44c7-8ac4-4bde56536565",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Miguel\\AppData\\Local\\Temp\\ipykernel_5720\\2487002278.py:2: UserWarning: Column names longer than 10 characters will be truncated when saved to ESRI Shapefile.\n",
      "  Recuento_mpios2021.to_file(\"C:/Users/Miguel/Documents/P_Col/info_desastres_py/IFINAL_Recuento_mpios2021\", driver='ESRI Shapefile')\n",
      "C:\\Users\\Miguel\\anaconda3\\Lib\\site-packages\\pyogrio\\raw.py:723: RuntimeWarning: Normalized/laundered field name: 'COD_DEP_MUN' to 'COD_DEP_MU'\n",
      "  ogr_write(\n",
      "C:\\Users\\Miguel\\anaconda3\\Lib\\site-packages\\pyogrio\\raw.py:723: RuntimeWarning: Normalized/laundered field name: 'MAS_FALLECI' to 'MAS_FALLEC'\n",
      "  ogr_write(\n"
     ]
    }
   ],
   "source": [
    "# #Adicional pre reporte final\n",
    "# Recuento_mpios2021.to_file(\"C:/Users/Miguel/Documents/P_Col/info_desastres_py/IFINAL_Recuento_mpios2021\", driver='ESRI Shapefile')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "0ddf62af",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# #Exporto el dataframe de 2021 hasta acá que es el que se va a  procesamiento con MCS\n",
    "\n",
    "# #Renombro algunas columnas TIPO DE EVENTO-> TIPO_EVENTO, DESAPARECIDOS-> DESAPA, VIVIENDAS DESTRUIDAS -> VIV_DESTRU\n",
    "#    #..., VIVIENDAS AVERIADAS -> VIV_AVERI, CÓDIGO DANE DEL MUNICIPIO -> COD_DANE_MP\n",
    "    \n",
    "# #Renombrar columnas en el DataFrame\n",
    "# desastres_2021.rename(columns={\n",
    "#     'TIPO DE EVENTO': 'TIPO_EVENTO',\n",
    "#     'DESAPARECIDOS': 'DESAPA',\n",
    "#     'VIVIENDAS DESTRUIDAS': 'VIV_DESTRU',\n",
    "#     'VIVIENDAS AVERIADAS': 'VIV_AVERI',\n",
    "#     'CÓDIGO DANE DEL MUNICIPIO': 'COD_DANE_MP',\n",
    "#     'DEPARTAMENTO':'DEPTO'\n",
    "# }, inplace=True)\n",
    "\n",
    "\n",
    "# #También creo una nueva columna para identificar cada fila\n",
    "# # Función para generar un código aleatorio de 4 números y 4 letras\n",
    "# def generar_id_desastre():\n",
    "#     numeros = ''.join(random.choices(string.digits, k=4))\n",
    "#     letras = ''.join(random.choices(string.ascii_uppercase, k=4))\n",
    "#     return numeros + letras\n",
    "\n",
    "# # Generamos los Ids y verificamos que no haya duplicados\n",
    "# ids_generados = set()\n",
    "# def generar_ids_unicos():\n",
    "#     nuevo_id = generar_id_desastre()\n",
    "#     while nuevo_id in ids_generados:\n",
    "#         nuevo_id = generar_id_desastre()\n",
    "#     ids_generados.add(nuevo_id)\n",
    "#     return nuevo_id\n",
    "\n",
    "# # Creamos la nueva columna 'Id_desastres' aplicando la función\n",
    "# desastres_2021['ID_DESASTRES'] = [generar_ids_unicos() for _ in range(len(desastres_2021))]\n",
    "\n",
    "# # Mover la columna 'Id_desastres' a la primera posición\n",
    "# columnas = ['ID_DESASTRES'] + [col for col in desastres_2021.columns if col != 'Id_desastres']\n",
    "# desastres_2021 = desastres_2021[columnas]\n",
    "\n",
    "# #Exporto el dataframe:\n",
    "# desastres_2021.to_csv('Datos_desastres/desastres_2001_2021.csv',index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
