{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a3d774be",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Este notebook se utiliza para el procesamiento de análisis de los desastres con los MCS (2001-2021) día del desastre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "651a3199",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #importamos las librerías a utilizar\n",
    "# import pandas as pd\n",
    "# import numpy as np\n",
    "# import matplotlib.pyplot as plt\n",
    "# from matplotlib.patches import Rectangle\n",
    "# import matplotlib.patches as mpatches\n",
    "# import seaborn as sns \n",
    "# import datetime\n",
    "# import calendar\n",
    "# import matplotlib.dates as mdates\n",
    "# import geopandas as gpd\n",
    "# from shapely import wkt\n",
    "# from pandas.tseries.offsets import Day\n",
    "# from datetime import timedelta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "05f96b0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Para DESASTRES\n",
    "\n",
    "# #leemos el dataframe de desastres\n",
    "# df_desastres=pd.read_csv('Datos_desastres/desastres_2001_2021.csv', encoding='UTF-8')\n",
    "\n",
    "# #Aseguramos de tener la columna 'FECHA'(yyy-mm-dd) en formato de fecha \n",
    "# df_desastres['FECHA'] = pd.to_datetime(df_desastres['FECHA'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0791f030",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Leo el shape del DANE para llevarlo a csv y también lo exporto a la carpeta como shape\n",
    "\n",
    "# #Cargar el shapefile de DANE, Datos de municipio oficiales del portal\n",
    "# dane_shp = gpd.read_file(\"MGN2023_MPIO_POLITICO/MGN_ADM_MPIO_GRAFICO.shp\")\n",
    "\n",
    "\n",
    "# #Exporto como shape a la carpeta local a utilizar\n",
    "# dane_shp.to_file('Datos_DANE/dane_mpios_shape', driver='ESRI Shapefile')\n",
    "\n",
    "\n",
    "# #Lo convierto a csv para que ese sea el listado de mpios de colombia\n",
    "\n",
    "# # primero elimino la columna geometría, ya que no puede ser exportada directamente a CSV\n",
    "# dane_mpios = dane_shp.drop(columns='geometry')\n",
    "\n",
    "# # Exportar a CSV \n",
    "# dane_mpios.to_csv('Datos_DANE/dane_mpios.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e103efe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Leemos el archivo del dane recién creado\n",
    "\n",
    "# #Este es el archivo donde se almacenan todos los mpios de Colombia\n",
    "# colombia_mpios=pd.read_csv('Datos_DANE/dane_mpios.csv', encoding='UTF-8')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2668ad53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #PARA MCS \n",
    "\n",
    "#  #Para gdf\n",
    "    \n",
    "# #Leo el archivo shapefile de mpios DANE\n",
    "# mpios_shp = gpd.read_file('Datos_DANE/dane_mpios_shape/dane_mpios_shape.shp')\n",
    "# #lo reproyecto a coordenadas mundiales\n",
    "# mpios_shp=mpios_shp.to_crs(4326)\n",
    "\n",
    "# #Leo archivo de climatología de MCS\n",
    "# mcs= pd.read_csv('Datos_MCS/MCS_2001_2020.csv',sep=',', parse_dates=['time'])\n",
    "# #Convierto la geometry de texto plano a polígonos reales\n",
    "# mcs['geometry']=mcs['geometry'].apply(wkt.loads)\n",
    "# #reproyecto los mcs a coordenadas munciales\n",
    "# mcs2=gpd.GeoDataFrame(mcs, crs='epsg:4326')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c4661c14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Creamos una función para el análisis de intersección de los MCS con cada municipio en colombia\n",
    "#  #Esta función verifica si el MCS pasó por el mpio de análisis\n",
    "\n",
    "\n",
    "# def analisis_mpios_shp(mpio):\n",
    "    \n",
    "#     #defino la intersección en el municipio de analisis\n",
    "#     inters=mcs2['geometry'].intersects(mpios_shp.iloc[mpio].geometry)\n",
    "    \n",
    "#     #creamos una copia del mcs2 para no alterar el original\n",
    "#     mcs2_b=mcs2.copy()\n",
    "    \n",
    "#     #Insertamos el valor booleano en una nueva columna para ver si la fila se interesecta o no con el mpio de analisis\n",
    "#     mcs2_b['BOOL']=inters\n",
    "    \n",
    "#     # Creamos una nueva columna para el día y la hora\n",
    "#     mcs2_b['day'] = pd.to_datetime(mcs2_b['time']).dt.date\n",
    "#     #Me aseguro que esté en el mismo formato de día que los desastres\n",
    "#     mcs2_b['day']=pd.to_datetime(mcs2_b['day'])\n",
    "#     mcs2_b['hour'] = pd.to_datetime(mcs2_b['time']).dt.time\n",
    "    \n",
    "#     #Filtro mcs2_b para solo dejar las filas donde el mcs se interescta con el mpio (BOOL=TRUE)\n",
    "#     mcs2_b=mcs2_b[mcs2_b['BOOL']==True]\n",
    "    \n",
    "#     #Cambio el nombre de la primera columna que está sin nombre\n",
    "#     mcs2_b=mcs2_b.rename(columns={mcs2_b.columns[0]:'Id_mcs'})\n",
    "\n",
    "#     # Agrego columnas del nombre del municipio y código del municipio para diferenciarlos en la gráfica\n",
    "#     mcs2_b['nombr_mpio'] = colombia_mpios.iloc[mpio]['mpio_cnmbr']\n",
    "\n",
    "#     mcs2_b['cod_mpio'] = colombia_mpios.iloc[mpio]['mpio_cdpmp']\n",
    "    \n",
    "#     return mcs2_b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1779dc90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # RESULTADOS solo MCS\n",
    "# #Este código es para obtener los MCS que sucedieron en los mpios de Colombia (2001-2021)\n",
    "#  #   Se usa la función analisis_mpios_shp\n",
    "\n",
    "# #Lista para agregar el análisis de MCS en cada mpio de Colombia\n",
    "# lista_mcs= []\n",
    "\n",
    "# #Ciclo para analizar cada mpio y almacenarlo en la lista\n",
    "# for mpio in range(len(colombia_mpios)):\n",
    "#     mpio_analisis = analisis_mpios_shp(mpio)\n",
    "#     lista_mcs.append(mpio_analisis)\n",
    "\n",
    "\n",
    "# #Concatenamos la lista para obtener un solo dataframe \n",
    "# df_mcs_concat=pd.concat(lista_mcs, ignore_index=True)\n",
    "\n",
    "\n",
    "# #QUITAR COMENTADO CUANDO VAYA A CORRERLO TODO\n",
    "\n",
    "#YA SE CORRIÓ, se exporta como: 'Resultados_dataframes/MCS_pol_totales.csv.gz'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cacc0364",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#YA SE CORRIÓ\n",
    "\n",
    "#Exporto el df_mcs_concat como un archivo comprimido y lo llamo MCS_pol_totales, porque son el tota de polígonos...\n",
    "   #de Sistemas convectivos de mesoescala que sucedieron en los municipios de Colombia\n",
    "# df_mcs_concat.to_csv('Resultados_dataframes/MCS_pol_totales.csv.gz', compression='gzip', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5f7c9b70",
   "metadata": {},
   "outputs": [],
   "source": [
    "#YA SE CORRIÓ\n",
    "\n",
    "#Cargo el archivo de MCS_pol_totales \n",
    "#MCS_pol_totales = pd.read_csv('Resultados_dataframes/MCS_pol_totales.csv.gz', compression='gzip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "741db7f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#YA SE CORRIÓ\n",
    "\n",
    "#Obtengo la cantidad de polígonos que pasó por cada municipio para hacer la gráfica de distribución de MCS\n",
    "\n",
    "# Agrupar por código del municipio y contar la cantidad de MCS\n",
    "#mcs_por_municipio = MCS_pol_totales.groupby(['cod_mpio', 'nombr_mpio']).size().reset_index(name='num_MCS')\n",
    "\n",
    "#Exporto como csv para graficar en QGIS\n",
    "#mcs_por_municipio.to_csv('Resultados_dataframes/MCS_por_municipio.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d41903ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # MCS únicos totales que sucedieron en Colombia (no polígonos)\n",
    "\n",
    "#     #Se eliminan los duplicados de track id para saber la cantidad de sistemas presentes en Colombia\n",
    "\n",
    "# mcs_totales= df_mcs_concat.drop_duplicates(subset='track_id')\n",
    "# mcs_totales.to_csv('Resultados_dataframes/MCS_No_Pol_totales.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b4e4bd9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Creamos la función para el análisis de coincidencia entre desastres y MCS (mismo día)\n",
    "\n",
    "# def coincidencia(num):\n",
    "#     #Obtengo el código del mpio correspondiente al mpio (num)\n",
    "#     mpio_selec=colombia_mpios.loc[num, 'mpio_cdpmp']\n",
    "    \n",
    "#     #Filtrar df desastres para seleccionar solo el codigo del municipio de analisis\n",
    "#     desastres_fn=df_desastres[df_desastres['COD_DEP_MUN']==mpio_selec]\n",
    "    \n",
    "#     #obtenemos un df que contiene las filas donde en el mismo mpio coinciden mcs y desastres el mismo día\n",
    "#     df_analisis= pd.merge(desastres_fn,analisis_mpios_shp(num), left_on='FECHA', right_on='day', how='inner')\n",
    "#     return df_analisis\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f5e69c1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "##YA SE CORRIÓ\n",
    "\n",
    "# #RESULTADO PRINCIPAL: Coincidencia de desastres con MCS\n",
    "\n",
    "# #Inicializamos una lista vacía para almacenar los resultados de cada municipio(df) \n",
    "\n",
    "#   #Resultado: mcs que coinciden con desastres naaturales en el mismo día:\n",
    "    \n",
    "# lista_myd = []\n",
    "\n",
    "# # Creamos ciclo para analizar la coincidencia de cada mpio y almacenarlo en la lista\n",
    "# for mpio in range(len(colombia_mpios)):\n",
    "#     analisis_myd = coincidencia(mpio)\n",
    "#     lista_myd.append(analisis_myd)\n",
    "    \n",
    "\n",
    "# # Concatenamos todos los DataFrames de la lista en uno solo\n",
    "\n",
    "# coincidencia_mcs_desastres = pd.concat(lista_myd, ignore_index=True)\n",
    "\n",
    "# # #Este es el dataframe principal, que nos da los MCS que coincidieron con desastres naturales en\n",
    "# #  #  ...Colombia durante el periodo de analisis (2001-2021)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "73eb9caf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#YA SE CORRIÓ\n",
    "# #Exporto el df coincidencia_mcs_desastres como un archivo comprimido con nombre MCS_desastres_1dia\n",
    "   \n",
    "#     #Este DF contiene todos los desastres que coinciden con MCS el mismo día\n",
    "    \n",
    "# coincidencia_mcs_desastres.to_csv('Resultados_dataframes/MCS_desastres_1dia.csv.gz', compression='gzip', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "45d4c708",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Cargo el archivo de MCS_desastres_1dia\n",
    "\n",
    "# MCS_desastres_1dia = pd.read_csv('Resultados_dataframes/MCS_desastres_1dia.csv.gz', compression='gzip',  dtype={5: str},  low_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "69d47e55",
   "metadata": {},
   "outputs": [],
   "source": [
    "#YA SE CORRIÓ\n",
    "\n",
    "##Desastres con presencia de MCS\n",
    "\n",
    "# #Esta línea da los desastres únicos con presencia de MCS, solo se tiene en cuenta un MCS, porque lo importante es ver los ...\n",
    "#  #desastres que tienen presencia de MCS y no cuántos polígonos de MCS estuvieron presentes\n",
    "    \n",
    "# desastres_unicos_mcs=MCS_desastres_1dia.drop_duplicates(subset='ID_DESASTRES')\n",
    "\n",
    "# desastres_unicos_mcs.to_csv('Resultados_dataframes/desastres_unicos_mcs.csv.gz', compression='gzip', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "06923e3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# YA SE CORRIÓ\n",
    "# #sistemas convectivos de mesoescala (MCS) totales -no polígonos- que sucedieron en los desastres\n",
    "\n",
    "#     #Se eliminan los track_id repetidos para ver cuántos fueron en total los MCS involucrados en desastres\n",
    "\n",
    "# MCS_unicos_desastres=coincidencia_mcs_desastres.drop_duplicates(subset='track_id')\n",
    "# MCS_unicos_desastres.to_csv('Resultados_dataframes/MCS_unicos_desastres.csv.gz', compression='gzip', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3e8ccf5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#PARA ANÁLISIS DE 3 DÍAS ANTES: ------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "49cff068",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Se crea dataframe con desastres de hasta 3 días antes\n",
    "\n",
    "\n",
    "# # Asegurarse de que la columna FECHA es de tipo datetime\n",
    "# df_desastres['FECHA'] = pd.to_datetime(df_desastres['FECHA'])\n",
    "\n",
    "# # Creamos una lista vacía para almacenar las nuevas filas\n",
    "# nuevas_filas = []\n",
    "\n",
    "# # Iterar sobre cada fila del DataFrame original\n",
    "# for _, row in df_desastres.iterrows():\n",
    "#     # Iterar sobre los días de -3 a 0\n",
    "#     for dias in range(-3, 1):\n",
    "#         # Crear una copia de la fila original\n",
    "#         nueva_fila = row.copy()\n",
    "#         # Modificar la columna FECHA_ADIC con la nueva fecha\n",
    "#         nueva_fila['FECHA_ADIC'] = row['FECHA'] + timedelta(days=dias)\n",
    "#         # Agregar la nueva fila a la lista\n",
    "#         nuevas_filas.append(nueva_fila)\n",
    "\n",
    "# # Crear el nuevo DataFrame a partir de las nuevas filas\n",
    "# df_desastres_3d = pd.DataFrame(nuevas_filas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1665c9ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Se define función de coincidencia para 3 días antes:\n",
    "\n",
    "# def coincidencia_3d(num):\n",
    "#     #Obtengo el código del mpio correspondiente al mpio (num)\n",
    "#     mpio_selec=colombia_mpios.loc[num, 'mpio_cdpmp']\n",
    "    \n",
    "#     #Filtrar df desastres para seleccionar solo el codigo del municipio de analisis\n",
    "#     desastres_fn=df_desastres_3d[df_desastres_3d['COD_DEP_MUN']==mpio_selec]\n",
    "    \n",
    "#     #obtenemos un df que contiene las filas donde en el mismo mpio coinciden mcs y desastres el mismo día\n",
    "#     df_analisis= pd.merge(desastres_fn,analisis_mpios_shp(num), left_on='FECHA_ADIC', right_on='day', how='inner')\n",
    "#     return df_analisis\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4ffd5b68",
   "metadata": {},
   "outputs": [],
   "source": [
    "#YA SE CORRIÓ\n",
    "\n",
    "# #RESULTADO secundario: Coincidencia de desastres con MCS, 3 días antes\n",
    "\n",
    "# #Inicializamos una lista vacía para almacenar los resultados de cada municipio(df) \n",
    "\n",
    "# #   #Resultado: mcs que coinciden con desastres naaturales hasta 3 días antes\n",
    "    \n",
    "# lista_myd_3d = []\n",
    "\n",
    "# # # Creamos ciclo para analizar la coincidencia de cada mpio y almacenarlo en la lista\n",
    "# for mpio in range(len(colombia_mpios)):\n",
    "#     analisis_myd_3d = coincidencia_3d(mpio)\n",
    "#     lista_myd_3d.append(analisis_myd_3d)\n",
    "    \n",
    "\n",
    "#  # Concatenamos todos los DataFrames de la lista en uno solo\n",
    "\n",
    "# coincidencia_mcs_desastres_3d = pd.concat(lista_myd_3d, ignore_index=True)\n",
    "\n",
    "#dataframe secundario, que nos da los MCS que coincidieron con desastres naturales en\n",
    " #  ...Colombia durante el periodo de analisis (2001-2021), 3 días antes del desastre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "eeb80bdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "## YA CORRIÓ\n",
    "# #Guardo el dataframe de coincidencia de 3 días antes\n",
    "# coincidencia_mcs_desastres_3d.to_csv('Resultados_dataframes/MCS_desastres_3d.csv.gz', compression='gzip', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a81b2ec4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargo el archivo de MCS_desastres_3d para obtener análisis necesarios\n",
    "\n",
    "MCS_desastres_3d = pd.read_csv('Resultados_dataframes/MCS_desastres_3d.csv.gz', compression='gzip',  dtype={5: str},  low_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4f33ecfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#YA SE CORRIÓ \n",
    "\n",
    "# #Resultados adicionales para 3 DÍAS ANTES\n",
    "\n",
    "# #Desastres con presencia de MCS\n",
    "# desastres_unicos_mcs_3d=coincidencia_mcs_desastres_3d.drop_duplicates(subset='ID_DESASTRES')\n",
    "\n",
    "# #sistemas convectivos de mesoescala (MCS) totales -no polígonos- que sucedieron en los desastres\n",
    "# MCS_unicos_desastres_3d=coincidencia_mcs_desastres_3d.drop_duplicates(subset='track_id')\n",
    "\n",
    "# #Guardo los dataframes obtenidos\n",
    "# desastres_unicos_mcs_3d.to_csv('Resultados_dataframes/desastres_unicos_mcs_3d.csv.gz', compression='gzip', index=False)\n",
    "# MCS_unicos_desastres_3d.to_csv('Resultados_dataframes/MCS_unicos_desastres_3d.csv.gz', compression='gzip', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7f1f86a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#PARA ANALISIS 3 DÍAS DESPUES ---------------------------\n",
    "\n",
    " #Se hace para comparar rsultados\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "179f4275",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Se crea dataframe con desastres de  4 días después \n",
    "\n",
    "# # Supongamos que df_desastres es tu DataFrame original que contiene los desastres\n",
    "# # Asegurarse de que la columna FECHA es de tipo datetime\n",
    "# df_desastres['FECHA'] = pd.to_datetime(df_desastres['FECHA'])\n",
    "\n",
    "# # Creamos una lista vacía para almacenar las nuevas filas\n",
    "# nuevas_filas = []\n",
    "\n",
    "# # Iterar sobre cada fila del DataFrame original\n",
    "# for _, row in df_desastres.iterrows():\n",
    "#     # Iterar sobre los días de 1 a 4\n",
    "#     for dias in range(1, 5):\n",
    "#         # Crear una copia de la fila original\n",
    "#         nueva_fila = row.copy()\n",
    "#         # Modificar la columna FECHA_ADIC con la nueva fecha\n",
    "#         nueva_fila['FECHA_ADIC'] = row['FECHA'] + timedelta(days=dias)\n",
    "#         # Agregar la nueva fila a la lista\n",
    "#         nuevas_filas.append(nueva_fila)\n",
    "\n",
    "# # Crear el nuevo DataFrame a partir de las nuevas filas\n",
    "# df_desastres_3p = pd.DataFrame(nuevas_filas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "606b9808",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Se define función de coincidencia para 3 días después:\n",
    "\n",
    "# def coincidencia_3p(num):\n",
    "#     #Obtengo el código del mpio correspondiente al mpio (num)\n",
    "#     mpio_selec=colombia_mpios.loc[num, 'mpio_cdpmp']\n",
    "    \n",
    "#     #Filtrar df desastres para seleccionar solo el codigo del municipio de analisis\n",
    "#     desastres_fn=df_desastres_3p[df_desastres_3p['COD_DEP_MUN']==mpio_selec]\n",
    "    \n",
    "#     #obtenemos un df que contiene las filas donde en el mismo mpio coinciden mcs y desastres el mismo día\n",
    "#     df_analisis= pd.merge(desastres_fn,analisis_mpios_shp(num), left_on='FECHA_ADIC', right_on='day', how='inner')\n",
    "#     return df_analisis\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "9ffa6a78",
   "metadata": {},
   "outputs": [],
   "source": [
    "#YA SE CORRIÓ\n",
    "# #RESULTADO de soporte: Coincidencia de desastres con MCS, 4 días después\n",
    "\n",
    "# #Inicializamos una lista vacía para almacenar los resultados de cada municipio(df) \n",
    "\n",
    "# #   #Resultado: mcs que coinciden con desastres naaturales hasta 3 días antes\n",
    "    \n",
    "# lista_myd_3p = []\n",
    "\n",
    "# # # Creamos ciclo para analizar la coincidencia de cada mpio y almacenarlo en la lista\n",
    "# for mpio in range(len(colombia_mpios)):\n",
    "#     analisis_myd_3p = coincidencia_3p(mpio)\n",
    "#     lista_myd_3p.append(analisis_myd_3p)\n",
    "    \n",
    "\n",
    "#  # Concatenamos todos los DataFrames de la lista en uno solo\n",
    "\n",
    "# coincidencia_mcs_desastres_3p = pd.concat(lista_myd_3p, ignore_index=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c3a7195a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Guardo el dataframe de coincidencia de 4 días después\n",
    "#coincidencia_mcs_desastres_3p.to_csv('Resultados_dataframes/MCS_desastres_3p.csv.gz', compression='gzip', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "549a01ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Cargo el archivo de MCS_desastres_3P para obtener análisis necesarios\n",
    "\n",
    "# MCS_desastres_3p = pd.read_csv('Resultados_dataframes/MCS_desastres_3p.csv.gz', compression='gzip',  dtype={5: str},  low_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "f24c125f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Resultados adicionales para 4 DÍAS DESPUÉS\n",
    "\n",
    "# #Desastres con presencia de MCS\n",
    "# desastres_unicos_mcs_3p=MCS_desastres_3p.drop_duplicates(subset='ID_DESASTRES')\n",
    "# desastres_unicos_mcs_3p.to_csv('Resultados_dataframes/desastres_unicos_mcs_3p.csv.gz', compression='gzip', index=False)\n",
    "\n",
    "# #sistemas convectivos de mesoescala (MCS) totales -no polígonos- que sucedieron en los desastres\n",
    "# MCS_unicos_desastres_3p=MCS_desastres_3p.drop_duplicates(subset='track_id')\n",
    "# MCS_unicos_desastres_3p.to_csv('Resultados_dataframes/MCS_unicos_desastres_3p.csv.gz', compression='gzip', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "801bc09c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
